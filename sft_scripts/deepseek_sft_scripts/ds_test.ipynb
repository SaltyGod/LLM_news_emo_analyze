{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8714333",
   "metadata": {},
   "source": [
    "### **0420最新版本，注释的不用跑，后续要跑，prompt已改**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载基础模型...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正在加载基础模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 加载基础模型\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_bf16_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 加载tokenizer并添加特殊标记\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正在加载tokenizer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:571\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    570\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/modeling_utils.py:4399\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4390\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4392\u001b[0m     (\n\u001b[1;32m   4393\u001b[0m         model,\n\u001b[1;32m   4394\u001b[0m         missing_keys,\n\u001b[1;32m   4395\u001b[0m         unexpected_keys,\n\u001b[1;32m   4396\u001b[0m         mismatched_keys,\n\u001b[1;32m   4397\u001b[0m         offload_index,\n\u001b[1;32m   4398\u001b[0m         error_msgs,\n\u001b[0;32m-> 4399\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4408\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4417\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4418\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/modeling_utils.py:4833\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4831\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m   4832\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m-> 4833\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4847\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4851\u001b[0m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[1;32m   4852\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/modeling_utils.py:789\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    787\u001b[0m param \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 789\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[1;32m    791\u001b[0m     param \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from peft import PeftModel\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import os\n",
    "\n",
    "# # 设置模型路径\n",
    "# base_model_path = \"/root/.cache/LLMS/hub/hub/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B\"\n",
    "# lora_model_path = \"/root/LLM_news_emo_analyze/outputs/checkpoint-5534\"\n",
    "# merged_model_path = \"/root/LLM_news_emo_analyze/DeepSeek_output/DeepSeek-R1-NewsEmo-Merged2\"\n",
    "\n",
    "# # 创建保存目录\n",
    "# os.makedirs(merged_model_path, exist_ok=True)\n",
    "\n",
    "# print(\"正在加载基础模型...\")\n",
    "# # 加载基础模型\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model_path,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# # 加载tokenizer并添加特殊标记\n",
    "# print(\"正在加载tokenizer...\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
    "# special_tokens = {\"additional_special_tokens\": [\"<think>\", \"</think>\"]}\n",
    "# num_added_tokens = tokenizer.add_special_tokens(special_tokens)\n",
    "# print(f\"添加了 {num_added_tokens} 个特殊标记到tokenizer\")\n",
    "\n",
    "# # 调整模型以适应新的token\n",
    "# base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# print(\"正在加载LoRA模型...\")\n",
    "# # 加载LoRA模型\n",
    "# model = PeftModel.from_pretrained(base_model, lora_model_path)\n",
    "\n",
    "# print(\"正在合并模型...\")\n",
    "# # 合并模型\n",
    "# merged_model = model.merge_and_unload()\n",
    "\n",
    "# print(f\"正在保存合并后的模型到 {merged_model_path}...\")\n",
    "# # 保存合并后的模型和tokenizer\n",
    "# merged_model.save_pretrained(merged_model_path)\n",
    "# tokenizer.save_pretrained(merged_model_path)\n",
    "\n",
    "# print(\"模型合并完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad09e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39eb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局变量存储加载的模型和tokenizer\n",
    "global_model = None\n",
    "global_tokenizer = None\n",
    "\n",
    "def load_model(model_path=\"/root/LLM_news_emo_analyze/DeepSeek_output/DeepSeek-R1-NewsEmo-Merged\"):\n",
    "    \"\"\"\n",
    "    加载模型，只需调用一次\n",
    "    \n",
    "    参数:\n",
    "        model_path: 合并后模型的路径\n",
    "    \"\"\"\n",
    "    global global_model, global_tokenizer\n",
    "    \n",
    "    print(\"正在加载模型...\")\n",
    "    # 加载模型和tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    \n",
    "    # 确保tokenizer有正确的pad_token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # 保存到全局变量\n",
    "    global_model = model\n",
    "    global_tokenizer = tokenizer\n",
    "    \n",
    "    print(\"模型加载完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db180ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "def predict(prompt, temperature=0.1, max_length=4096, return_full=False):\n",
    "    \"\"\"\n",
    "    预测函数，自动拼接格式并返回结果\n",
    "    \n",
    "    参数:\n",
    "        prompt: 输入的问题或指令\n",
    "        temperature: 温度参数，控制生成的随机性，默认0.7\n",
    "        max_length: 最大生成长度，默认2048\n",
    "        return_full: 是否返回完整结果包含思考过程，默认False（只返回最终答案）\n",
    "        \n",
    "    返回:\n",
    "        如果return_full=False，返回最终答案字符串\n",
    "        如果return_full=True，返回包含思考过程和最终答案的字典\n",
    "    \"\"\"\n",
    "    global global_model, global_tokenizer\n",
    "    \n",
    "    # 检查模型是否已加载\n",
    "    if global_model is None or global_tokenizer is None:\n",
    "        load_model()\n",
    "    \n",
    "    # 格式化输入，与训练数据格式一致\n",
    "    formatted_prompt = f\"指令: {prompt}\\n\\n输出: \"\n",
    "    \n",
    "    # 编码输入\n",
    "    inputs = global_tokenizer(formatted_prompt, return_tensors=\"pt\").to(global_model.device)\n",
    "    \n",
    "    # 生成回答\n",
    "    with torch.no_grad():\n",
    "        outputs = global_model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=0.9,\n",
    "            do_sample=False,\n",
    "            pad_token_id=global_tokenizer.pad_token_id,\n",
    "            repetition_penalty=1.1,\n",
    "            # no_repeat_ngram_size=3,\n",
    "            eos_token_id=global_tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # 解码输出\n",
    "    full_response = global_tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    \n",
    "    response = full_response.split(\"输出: \")[-1]\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a74ec10",
   "metadata": {},
   "source": [
    "### **我自己的一个案例测试，你可以看看这个prompt格式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"**角色定义**\n",
    "擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分，请思考后回答。\n",
    "\n",
    "**核心任务**\n",
    "1. 分析新闻整体内容情绪\n",
    "2. 匹配情绪词典关键词\n",
    "3. 五档制评分（-1/-0.5/0/0.5/1）\n",
    "\n",
    "**评分逻辑**\n",
    "1. 语义匹配：忽略偏离词汇，保留有效情绪词\n",
    "2. 评分验证：整体语义优先，情绪词辅助修正\n",
    "\n",
    "**示例说明**\n",
    "- 示例1（积极）：\n",
    "新闻文本：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\n",
    "情绪词典：profitability:0.6,profit:0.8\n",
    "输出:<think>语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破。“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。</think> {\"情绪得分\":\"1\"}\n",
    "\n",
    "- 示例2（比较积极）：\n",
    "新闻文本：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\n",
    "情绪词典：mispricing:-0.4,advantage:0.7\n",
    "输出:<think>语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号。此外，新闻文本未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。</think> {\"情绪得分\":\"0.5\"}\n",
    "\n",
    "- 示例3（中性）：\n",
    "新闻文本：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\n",
    "情绪词典：free:0.2,immateriality:-0.2\n",
    "输出:<think>语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响。此外，新闻文本中“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。</think> {\"情绪得分\":\"0\"}\n",
    "\n",
    "- 示例4（比较消极）：\n",
    "新闻文本：我们投入的前期费用谁来承担\n",
    "情绪词典：invest:0.3\n",
    "输出:<think>语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪。新闻文本中“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。</think> {\"情绪得分\":\"-0.5\"}\n",
    "\n",
    "- 示例5（消极）：\n",
    "新闻文本：饱受美国次贷危机冲击的华尔街再次风云突变\n",
    "情绪词典：crash:-0.9,meltdown:-0.8\n",
    "输出:<think>语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分，符合-1的情绪评分。</think> {\"情绪得分\":\"-1\"}\n",
    "\n",
    "\n",
    "**输出规范**\n",
    "- 得分五档制强制选择\n",
    "- 输出格式：{\"情绪得分\":\"...\"}\n",
    "\n",
    "现在请你开始进行分析，严格按照输出规范输出结果，情绪词典分值仅作语义方向参考：\n",
    "新闻文本：而福喜集团总部所在地的美国，更被称作是全球食品安全监管体系最完善的国家之一，其着力于事前监管，把对食品安全的监管起点推进到田间和生产商，并且，由中央财政统一拨款，独立的检验运作核算功能，使不法企业难以蠢蠢欲动\n",
    "情绪词典：perfect:1.0, food:0.0\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8299ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型...\n",
      "模型加载完成！\n"
     ]
    }
   ],
   "source": [
    "load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9e5a19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>好的，我现在需要分析给定的新闻文本，并根据提供的情绪词典和评分逻辑给出五档制的情绪得分。首先，我得仔细阅读新闻内容，理解其整体情绪倾向。\n",
      "\n",
      "新闻内容提到福喜集团总部在美国，该国是全球食品安全监管最完善的地方。他们通过事前监管、独立检验和中央财政拨款，确保食品安全，防止不法企业存在。这里的关键点在于强调了安全监管的完善和独立运作，以及中央财政的统一拨款，这些都显示出对安全措施的重视和严格执行。\n",
      "\n",
      "接下来，检查情绪词典里的关键词。情绪词典里有两个词：perfect（1.0）和food（0.0）。新闻中没有直接出现这两个词，但可能隐含其中。例如，“perfect”暗示了高效率和严格的监管，这可能对应情绪词中的positive方向。而“food”虽然在词典中是中性，但在新闻中并没有明显的负面词汇，所以可能不太适用。\n",
      "\n",
      "然后看评分逻辑。第一步是语义匹配，忽略偏离词汇。新闻中提到的是“食品安全监管体系最完善”，这里的“完善”可能对应“perfect”的高分，即0.6或者更高。第二步是评分验证，整体语义优先，情绪词辅助修正。如果新闻整体情绪偏向积极，情绪词的匹配可能会加强这一判断。\n",
      "\n",
      "结合以上分析，新闻主要是在描述一个成功的食品安全监管体系，强调了严格和高效，这属于积极的情绪。因此，情绪得分应该在中性基础上稍微偏积极，比如0.5或者0.6。\n",
      "\n",
      "不过，再仔细想想，新闻中提到的是“不法企业难以蠢蠢欲动”，也就是避免不法行为，这可能暗示了一种积极的监管环境，但整体情绪是否是中性呢？或者是否有其他因素？\n",
      "\n",
      "另外，新闻中提到的是“中央财政统一拨款”，这可能意味着监管机构的统一协调，增加了透明性和公正性，这也是积极的信号。综合来看，整体情绪应该是积极的，但需要确认是否符合中性评分的范围。\n",
      "\n",
      "根据评分逻辑，虽然没有直接匹配情绪词，但“完善”和“统一拨款”可能暗示积极的监管措施，所以情绪词典中的“perfect”可能增强积极因素，但整体情绪还是中性的，因为没有明显的负面词汇。\n",
      "\n",
      "综上所述，情绪得分应为0.5。\n",
      "</think> {\"情绪得分\":\"0.5\"}<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "full_result = predict(prompt, return_full=True)\n",
    "print(full_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b8bdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "score_pattern = r'{\"情绪得分\"\\s*:\\s*\"([^\"]+)\"}'\n",
    "\n",
    "match = re.search(score_pattern, full_result)\n",
    "if match:\n",
    "    score_str = match.group(1)\n",
    "    print(float(score_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce80190",
   "metadata": {},
   "source": [
    "### **lhl单程尝试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理 500 行数据...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/root/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      " 20%|██        | 100/500 [1:12:35<1:51:46, 16.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "处理进度: 100/500 (20.00%)\n",
      "当前成功率: 80/100 (80.00%)\n",
      "\n",
      "最新处理记录:\n",
      "索引: 99\n",
      "@mufeng622：一边实名购票，一边“黄牛”遍地，搞笑至极\n",
      "fare:0.4, problematic:-0.5\n",
      "模型输出: <think>好的，我现在需要处理这个用户的查询，分析给定的新闻文本的情绪，并给出五档制评分。首先，我得仔细阅读用户提供的所有信息，确保自己完全理解任务的要求和评分逻辑。\n",
      "\n",
      "首先看角色定义部分，用户希望我作为中英双语的市场情绪分析专家，对中文市场的新闻文本进行情绪评分。核心任务包括三个步骤：分析整体内容情绪、匹配情绪词典关键词，以及按照评分逻辑给出五档分数。评分逻辑分为语义匹配和评分验证两个部分。\n",
      "\n",
      "接下来，看看示例，比如示例1是关于中信证券成为业内第一的新闻，情绪词典中有profitability和profit的高分词。输出是1分，因为这两词都支持积极的结果。而示例2则是关于A股被贴价，虽然没有直接的匹配词，但整体情绪是乐观的，所以评分是0.5分。\n",
      "\n",
      "现在来看具体的新闻文本：“@mufeng622：一边实名购票，一边‘黄牛’遍地，搞笑至极。” 这里的关键点在于“实名购票”和“‘黄牛’遍地”。实名购票通常意味着身份验证，可能带来信任感，而“黄牛”通常指不道德的人，可能暗示不道德行为。这里“黄牛”可能被用来比喻某些人或行为，导致负面情绪。\n",
      "\n",
      "情绪词典里有“fear”对应-0.5，但这里并没有直接出现这个词。不过“黄牛”可能隐含负面情绪，因为“黄牛”通常指的是不道德的人，可能在社交媒体上被用来形容某些人的行为，导致负面情绪。因此，结合整体语义，这可能是一个中性或者稍微负面的新闻。\n",
      "\n",
      "接下来检查是否有匹配情绪词典中的关键词。新闻中没有提到任何情绪词典中的词，比如“mispricing”或“advantage”，所以情绪词典中的词可能无法提供有效的匹配。但是，整体语义是带有负面情绪的，因为“黄牛”可能暗示负面行为，但具体是否达到中性或负面还需要看上下文。\n",
      "\n",
      "根据评分逻辑，第一步是语义匹配。这里没有直接匹配的情绪词典中的词，但“黄牛”可能暗示负面情绪，所以情绪词可能有一定的负面倾向。第二步是评分验证，整体语义是负面的，但缺乏明确的负面词典词，所以可能只能处于中性或稍微负面的位置。\n",
      "\n",
      "综合来看，这条新闻传达的是负面情绪，特别是“黄牛”可能暗示不道德或负面的行为，但缺乏足够的负面词汇来确定极端负面。因此，情绪得分应该是在中性到负面之间，可能接近中性，即0.5分。\n",
      "\n",
      "最后，检查输出规范，只需要给出情绪得分，所以最终评分应该是0.5。\n",
      "</think> {\"情绪得分\":\"0.5\"}<｜end▁of▁sentence｜>\n",
      "提取的分数: 0.5\n",
      "重试次数: 0\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 200/500 [2:26:45<2:18:46, 27.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "处理进度: 200/500 (40.00%)\n",
      "当前成功率: 161/200 (80.50%)\n",
      "\n",
      "最新处理记录:\n",
      "索引: 199\n",
      "亚太经济区域是全世界经济发展最为活跃的地区，而澳门虽然是一个微型经济体，但由于经济实力的快速增长，成为该区域内一个引人注目的亮点\n",
      "economy:0.0, region:0.0\n",
      "模型输出: <think>好的，我现在需要分析给定的新闻文本，并根据提供的情绪词典和评分逻辑给出五档制评分。首先，我得仔细阅读新闻内容，理解其整体情绪。\n",
      "\n",
      "新闻文本是关于亚太经济区域和澳门作为微型经济体的情况。提到澳门因为经济实力快速增长而成为亮点，这可能暗示其在经济领域具有吸引力。接下来，检查情绪词典里的关键词，这里有两个词：economy和region，对应的分数都是0.0。\n",
      "\n",
      "然后按照评分逻辑，先看整体语义。新闻中提到经济实力快速增长，这通常是积极的信号，比如经济繁荣、增长潜力大等。虽然澳门作为一个微型经济体，但其快速发展的速度可能意味着其经济竞争力增强，属于积极因素。\n",
      "\n",
      "接下来看情绪词典中的关键词是否匹配。这里没有直接出现“economy”或“region”的具体词汇，只是用了一个“经济实力快速增长”。不过，虽然没有具体的词汇，但整体语义上已经显示出经济活力，属于积极的情绪。\n",
      "\n",
      "所以，综合考虑，新闻文本传达的是一个积极的发展趋势，经济实力快速增长，这可能带来经济繁荣和增长潜力，符合中性评分的一个方向。但因为没有明显的负面词汇，整体情绪还是偏向积极的。\n",
      "\n",
      "因此，评分应该在中性范围内，即0.0。\n",
      "</think> {\"情绪得分\":\"0\"}<｜end▁of▁sentence｜>\n",
      "提取的分数: 0.0\n",
      "重试次数: 0\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 209/500 [2:34:49<3:14:51, 40.18s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_dataframe_simple(df, prompt_template, max_retries=3, print_interval=100):\n",
    "    \"\"\"\n",
    "    简单循环处理DataFrame，一行一行调用predict函数，并定期打印结果\n",
    "    \n",
    "    参数:\n",
    "        df: 输入的DataFrame\n",
    "        prompt_template: 包含{cut_news}和{sentiment_dict_v2}占位符的模板\n",
    "        max_retries: 最大重试次数，默认为3\n",
    "        print_interval: 打印结果的间隔，默认每100条打印一次\n",
    "        \n",
    "    返回:\n",
    "        处理后的DataFrame，包含预测结果和提取的分数\n",
    "    \"\"\"\n",
    "    # 添加结果列\n",
    "    if 'lhl_ds_output' not in df.columns:\n",
    "        df['lhl_ds_output'] = None\n",
    "    if 'findal_score' not in df.columns:\n",
    "        df['findal_score'] = None\n",
    "    if 'retry_count' not in df.columns:\n",
    "        df['retry_count'] = 0\n",
    "    \n",
    "    # 定义正则表达式模式，用于提取情绪得分\n",
    "    score_pattern = r'{\"情绪得分\"\\s*:\\s*\"([^\"]+)\"}'\n",
    "    \n",
    "    # 创建进度条\n",
    "    print(f\"开始处理 {len(df)} 行数据...\")\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        row = df.iloc[idx]\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                \n",
    "                current_prompt = prompt_template.replace(\"{cut_news}\", str(row['cut_news'])).replace(\"{sentiment_dict_v2}\", str(row['sentiment_dict_v2']))\n",
    "                # print(current_prompt)\n",
    "                \n",
    "                # 调用predict函数进行预测\n",
    "                temperature = 0.1\n",
    "                response = predict(current_prompt, temperature=temperature)\n",
    "                # print(response)\n",
    "                \n",
    "                # 保存完整输出\n",
    "                df.at[idx, 'lhl_ds_output'] = response\n",
    "                \n",
    "                # 提取情绪得分\n",
    "                match = re.search(score_pattern, response)\n",
    "                if match:\n",
    "                    score_str = match.group(1)\n",
    "                    try:\n",
    "                        # 尝试转换为浮点数\n",
    "                        score = float(score_str)\n",
    "                        # 检查是否为有效得分\n",
    "                        if score in [-1.0, -0.5, 0.0, 0, 0.5, 1.0]:\n",
    "                            df.at[idx, 'findal_score'] = score\n",
    "                            df.at[idx, 'retry_count'] = retry_count\n",
    "                            break  # 成功提取，退出重试循环\n",
    "                        else:\n",
    "                            # 记录重试次数\n",
    "                            retry_count += 1\n",
    "                    except ValueError:\n",
    "                        # 无法转换为浮点数，记录重试次数\n",
    "                        retry_count += 1\n",
    "                else:\n",
    "                    # 未找到匹配，记录重试次数\n",
    "                    retry_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"处理第 {idx} 行时出错: {str(e)}\")\n",
    "                df.at[idx, 'lhl_ds_output'] = f\"ERROR: {str(e)}\"\n",
    "                retry_count += 1\n",
    "                time.sleep(1)  # 出错后稍作等待\n",
    "                \n",
    "            # 清理GPU缓存\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # 如果已经重试了最大次数但仍未成功提取分数\n",
    "            if retry_count >= max_retries:\n",
    "                df.at[idx, 'retry_count'] = retry_count\n",
    "                if pd.isna(df.at[idx, 'findal_score']):\n",
    "                    df.at[idx, 'findal_score'] = 'FAILED_AFTER_RETRIES'\n",
    "                break\n",
    "        \n",
    "        # 每隔print_interval条数据打印一次结果\n",
    "        if (idx + 1) % print_interval == 0 or idx == len(df) - 1:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"处理进度: {idx + 1}/{len(df)} ({(idx + 1)/len(df)*100:.2f}%)\")\n",
    "            \n",
    "            # 计算当前的成功率\n",
    "            current_success_count = len(df.iloc[:idx+1][df.iloc[:idx+1]['findal_score'].apply(lambda x: isinstance(x, float))])\n",
    "            print(f\"当前成功率: {current_success_count}/{idx + 1} ({current_success_count/(idx + 1)*100:.2f}%)\")\n",
    "            \n",
    "            # 打印最近处理的这条记录\n",
    "            print(\"\\n最新处理记录:\")\n",
    "            print(f\"索引: {idx}\")\n",
    "            print(f\"新闻文本: {str(row['cut_news'])[:100]}...\" if len(str(row['cut_news'])) > 100 else str(row['cut_news']))\n",
    "            print(f\"情绪词典: {str(row['sentiment_dict_v2'])[:100]}...\" if len(str(row['sentiment_dict_v2'])) > 100 else str(row['sentiment_dict_v2']))\n",
    "            print(f\"模型输出: {df.at[idx, 'lhl_ds_output']}\")\n",
    "            print(f\"提取的分数: {df.at[idx, 'findal_score']}\")\n",
    "            print(f\"重试次数: {df.at[idx, 'retry_count']}\")\n",
    "            print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # 统计最终成功率\n",
    "    success_count = len(df[df['findal_score'].apply(lambda x: isinstance(x, float))])\n",
    "    print(f\"\\n全部处理完成！成功率: {success_count}/{len(df)} ({success_count/len(df)*100:.2f}%)\")\n",
    "    print(f\"平均重试次数: {df['retry_count'].mean():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 确保已经导入必要的库和定义了predict函数\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_csv(\"/root/LLM_news_emo_analyze/wxy_use/deepseek_test_500_wxy_0420.csv\", encoding='utf_8_sig', lineterminator='\\n')\n",
    "    \n",
    "    # 设置prompt模板\n",
    "    prompt_template = \"\"\"**角色定义**\n",
    "擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分，请思考后回答。\n",
    "\n",
    "**核心任务**\n",
    "1. 分析新闻整体内容情绪\n",
    "2. 匹配情绪词典关键词\n",
    "3. 五档制评分（-1/-0.5/0/0.5/1）\n",
    "\n",
    "**评分逻辑**\n",
    "1. 语义匹配：忽略偏离词汇，保留有效情绪词\n",
    "2. 评分验证：整体语义优先，情绪词辅助修正\n",
    "\n",
    "**示例说明**\n",
    "- 示例1（积极）：\n",
    "新闻文本：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\n",
    "情绪词典：profitability:0.6,profit:0.8\n",
    "输出:<think>语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破。“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。</think> {\"情绪得分\":\"1\"}\n",
    "\n",
    "- 示例2（比较积极）：\n",
    "新闻文本：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\n",
    "情绪词典：mispricing:-0.4,advantage:0.7\n",
    "输出:<think>语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号。此外，新闻文本未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。</think> {\"情绪得分\":\"0.5\"}\n",
    "\n",
    "- 示例3（中性）：\n",
    "新闻文本：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\n",
    "情绪词典：free:0.2,immateriality:-0.2\n",
    "输出:<think>语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响。此外，新闻文本中“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。</think> {\"情绪得分\":\"0\"}\n",
    "\n",
    "- 示例4（比较消极）：\n",
    "新闻文本：我们投入的前期费用谁来承担\n",
    "情绪词典：invest:0.3\n",
    "输出:<think>语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪。新闻文本中“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。</think> {\"情绪得分\":\"-0.5\"}\n",
    "\n",
    "- 示例5（消极）：\n",
    "新闻文本：饱受美国次贷危机冲击的华尔街再次风云突变\n",
    "情绪词典：crash:-0.9,meltdown:-0.8\n",
    "输出:<think>语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分，符合-1的情绪评分。</think> {\"情绪得分\":\"-1\"}\n",
    "\n",
    "\n",
    "**输出规范**\n",
    "- 得分五档制强制选择\n",
    "- 输出格式：{\"情绪得分\":\"...\"}\n",
    "\n",
    "现在请你开始进行分析，严格按照输出规范输出结果，情绪词典分值仅作语义方向参考：\n",
    "新闻文本：{cut_news}\n",
    "情绪词典：{sentiment_dict_v2}\"\"\"\n",
    "    \n",
    "    # 处理数据，每100条打印一次\n",
    "    processed_df = process_dataframe_simple(df, prompt_template, max_retries=3, print_interval=100)\n",
    "    \n",
    "    # 保存结果\n",
    "    processed_df.to_csv(\"processed_data_simple.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d5f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型...\n",
      "模型加载完成！\n",
      "开始处理 500 行数据，分 11 个批次处理...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [13:14<00:00, 72.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！\n",
      "成功率: 500/500 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import time\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# def batch_predict(prompts, temperature=0.3, max_length=2048):\n",
    "#     \"\"\"\n",
    "#     批量预测函数，同时处理多个提示\n",
    "    \n",
    "#     参数:\n",
    "#         prompts: 提示列表\n",
    "#         temperature: 温度参数\n",
    "#         max_length: 最大生成长度\n",
    "        \n",
    "#     返回:\n",
    "#         预测结果列表\n",
    "#     \"\"\"\n",
    "#     global global_model, global_tokenizer\n",
    "    \n",
    "#     # 检查模型是否已加载\n",
    "#     if global_model is None or global_tokenizer is None:\n",
    "#         load_model()\n",
    "    \n",
    "#     # 格式化输入\n",
    "#     formatted_prompts = [f\"指令: {prompt}\\n\\n输出: \" for prompt in prompts]\n",
    "    \n",
    "#     # 编码输入 - 批量处理\n",
    "#     inputs = global_tokenizer(\n",
    "#         formatted_prompts, \n",
    "#         return_tensors=\"pt\",\n",
    "#         padding=True,\n",
    "#         truncation=True,\n",
    "#         max_length=2048\n",
    "#     ).to(global_model.device)\n",
    "    \n",
    "#     # 生成回答\n",
    "#     with torch.inference_mode():\n",
    "#         outputs = global_model.generate(\n",
    "#             inputs.input_ids,\n",
    "#             max_length=max_length,\n",
    "#             temperature=temperature,\n",
    "#             top_p=0.9,\n",
    "#             # do_sample=True,\n",
    "#             pad_token_id=global_tokenizer.pad_token_id,\n",
    "#             repetition_penalty=1.03,\n",
    "#             eos_token_id=global_tokenizer.eos_token_id\n",
    "#         )\n",
    "    \n",
    "#     # 解码输出\n",
    "#     results = [\n",
    "#         global_tokenizer.decode(output, skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "#         for output in outputs\n",
    "#     ]\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def process_dataframe(df, prompt_template, batch_size=16, max_retries=3):\n",
    "#     \"\"\"\n",
    "#     处理DataFrame，批量生成预测并提取分数，失败时重试\n",
    "    \n",
    "#     参数:\n",
    "#         df: 输入的DataFrame\n",
    "#         prompt_template: 包含{cut_news}和{sentiment_dict_v2}占位符的模板\n",
    "#         batch_size: 批处理大小，默认8\n",
    "#         max_retries: 最大重试次数，默认3\n",
    "        \n",
    "#     返回:\n",
    "#         处理后的DataFrame，包含预测结果和提取的分数\n",
    "#     \"\"\"\n",
    "#     # 添加结果列\n",
    "#     if 'lhl_ds_output' not in df.columns:\n",
    "#         df['lhl_ds_output'] = None\n",
    "#     if 'findal_score' not in df.columns:\n",
    "#         df['findal_score'] = None\n",
    "#     if 'retry_count' not in df.columns:\n",
    "#         df['retry_count'] = 0\n",
    "    \n",
    "#     # 定义正则表达式模式，用于提取情绪得分\n",
    "#     score_pattern = r'{\"情绪得分\"\\s*:\\s*\"([^\"]+)\"}'\n",
    "    \n",
    "#     # 计算需要处理的批次数\n",
    "#     total_rows = len(df)\n",
    "#     num_batches = (total_rows + batch_size - 1) // batch_size\n",
    "    \n",
    "#     print(f\"开始处理 {total_rows} 行数据，分 {num_batches} 个批次处理...\")\n",
    "    \n",
    "#     # 创建重试队列\n",
    "#     retry_indices = []\n",
    "    \n",
    "#     # 批量处理数据\n",
    "#     for batch_idx in tqdm(range(num_batches)):\n",
    "#         start_idx = batch_idx * batch_size\n",
    "#         end_idx = min(start_idx + batch_size, total_rows)\n",
    "        \n",
    "#         # 准备当前批次的提示\n",
    "#         batch_prompts = []\n",
    "#         batch_indices = []\n",
    "        \n",
    "#         for i in range(start_idx, end_idx):\n",
    "#             row = df.iloc[i]\n",
    "#             # 仅处理尚未成功提取分数的行\n",
    "#             if pd.isna(df.at[i, 'findal_score']) and df.at[i, 'retry_count'] < max_retries:\n",
    "#                 # 替换模板中的占位符\n",
    "#                 current_prompt = prompt_template.replace(\"{cut_news}\", str(row['cut_news'])).replace(\"{sentiment_dict_v2}\", str(row['sentiment_dict_v2']))\n",
    "#                 batch_prompts.append(current_prompt)\n",
    "#                 batch_indices.append(i)\n",
    "        \n",
    "#         # 如果没有需要处理的提示，跳过当前批次\n",
    "#         if not batch_prompts:\n",
    "#             continue\n",
    "        \n",
    "#         try:\n",
    "#             # 批量生成预测\n",
    "#             predictions = batch_predict(batch_prompts, temperature=0.3)\n",
    "#             # print(predictions)\n",
    "            \n",
    "#             # 处理预测结果\n",
    "#             for idx, prediction in zip(batch_indices, predictions):\n",
    "#                 # 保存完整输出\n",
    "#                 df.at[idx, 'lhl_ds_output'] = prediction\n",
    "                \n",
    "#                 # 提取情绪得分\n",
    "#                 match = re.search(score_pattern, prediction)\n",
    "#                 if match:\n",
    "#                     score_str = match.group(1)\n",
    "#                     try:\n",
    "#                         # 尝试转换为浮点数\n",
    "#                         score = float(score_str)\n",
    "#                         df.at[idx, 'findal_score'] = score\n",
    "#                         # 成功提取，不需要重试\n",
    "#                     except ValueError:\n",
    "#                         # 无法转换为浮点数，需要重试\n",
    "#                         df.at[idx, 'retry_count'] += 1\n",
    "#                         if df.at[idx, 'retry_count'] < max_retries:\n",
    "#                             retry_indices.append(idx)\n",
    "#                 else:\n",
    "#                     # 未找到匹配，需要重试\n",
    "#                     df.at[idx, 'retry_count'] += 1\n",
    "#                     if df.at[idx, 'retry_count'] < max_retries:\n",
    "#                         retry_indices.append(idx)\n",
    "            \n",
    "#             # 清理CUDA缓存\n",
    "#             torch.cuda.empty_cache()\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"处理批次 {batch_idx} 时出错: {str(e)}\")\n",
    "#             # 将整个批次添加到重试队列\n",
    "#             for idx in batch_indices:\n",
    "#                 df.at[idx, 'lhl_ds_output'] = f\"ERROR: {str(e)}\"\n",
    "#                 df.at[idx, 'retry_count'] += 1\n",
    "#                 if df.at[idx, 'retry_count'] < max_retries:\n",
    "#                     retry_indices.append(idx)\n",
    "            \n",
    "#             # 清理CUDA缓存\n",
    "#             torch.cuda.empty_cache()\n",
    "#             time.sleep(2)  # 出错后稍作等待\n",
    "    \n",
    "#     # 处理重试队列\n",
    "#     if retry_indices:\n",
    "#         print(f\"处理 {len(retry_indices)} 条需要重试的数据...\")\n",
    "        \n",
    "#         # 对需要重试的行单独处理\n",
    "#         for idx in tqdm(retry_indices):\n",
    "#             row = df.iloc[idx]\n",
    "#             remaining_retries = max_retries - df.at[idx, 'retry_count']\n",
    "            \n",
    "#             for retry in range(remaining_retries):\n",
    "#                 try:\n",
    "#                     # 替换模板中的占位符，增加重试提示\n",
    "#                     current_prompt = prompt_template.replace(\"{cut_news}\", str(row['cut_news'])).replace(\"{sentiment_dict_v2}\", str(row['sentiment_dict_v2']))\n",
    "                    \n",
    "#                     # 使用较低温度增加确定性\n",
    "#                     prediction = predict(current_prompt, temperature=0.3)\n",
    "#                     prediction = prediction.split(\"输出: \")[-1]\n",
    "                    \n",
    "#                     # 保存完整输出\n",
    "#                     df.at[idx, 'lhl_ds_output'] = prediction\n",
    "                    \n",
    "#                     # 提取情绪得分\n",
    "#                     match = re.search(score_pattern, prediction)\n",
    "#                     if match:\n",
    "#                         score_str = match.group(1)\n",
    "#                         try:\n",
    "#                             score = float(score_str)\n",
    "#                             df.at[idx, 'findal_score'] = score\n",
    "#                             # 成功提取，不需要继续重试\n",
    "#                             break\n",
    "#                         except ValueError:\n",
    "#                             # 记录重试次数\n",
    "#                             df.at[idx, 'retry_count'] += 1\n",
    "#                             continue\n",
    "#                     else:\n",
    "#                         # 记录重试次数\n",
    "#                         df.at[idx, 'retry_count'] += 1\n",
    "#                         continue\n",
    "                    \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"重试第 {idx} 行时出错: {str(e)}\")\n",
    "#                     df.at[idx, 'retry_count'] += 1\n",
    "#                     time.sleep(1)  # 出错后稍作等待\n",
    "                \n",
    "#                 # 每次重试后清理CUDA缓存\n",
    "#                 torch.cuda.empty_cache()\n",
    "    \n",
    "#     # 标记最终仍无法提取分数的行\n",
    "#     for i in range(len(df)):\n",
    "#         if pd.isna(df.at[i, 'findal_score']) and df.at[i, 'retry_count'] >= max_retries:\n",
    "#             df.at[i, 'findal_score'] = 'FAILED_AFTER_RETRIES'\n",
    "    \n",
    "#     print(\"处理完成！\")\n",
    "#     return df\n",
    "\n",
    "# # 使用示例\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 加载模型（仅需一次）\n",
    "#     load_model()\n",
    "    \n",
    "#     # 读取数据\n",
    "#     df = pd.read_csv(\"/root/LLM_news_emo_analyze/wxy_use/deepseek_test_500_wxy_0420.csv\", encoding='utf_8_sig', lineterminator='\\n')\n",
    "    \n",
    "#     # 设置prompt模板\n",
    "#     prompt_template = \"\"\"**角色定义**\n",
    "# 擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分，请思考后回答。\n",
    "\n",
    "# **核心任务**\n",
    "# 1. 分析新闻整体内容情绪\n",
    "# 2. 匹配情绪词典关键词\n",
    "# 3. 五档制评分（-1/-0.5/0/0.5/1）\n",
    "\n",
    "# **评分逻辑**\n",
    "# 1. 语义匹配：忽略偏离词汇，保留有效情绪词\n",
    "# 2. 评分验证：整体语义优先，情绪词辅助修正\n",
    "\n",
    "# **示例说明**\n",
    "# - 示例1（积极）：\n",
    "# 新闻文本：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\n",
    "# 情绪词典：profitability:0.6,profit:0.8\n",
    "# 输出:<think>语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破。“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。</think> {\"情绪得分\":\"1\"}\n",
    "\n",
    "# - 示例2（比较积极）：\n",
    "# 新闻文本：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\n",
    "# 情绪词典：mispricing:-0.4,advantage:0.7\n",
    "# 输出:<think>语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号。此外，新闻文本未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。</think> {\"情绪得分\":\"0.5\"}\n",
    "\n",
    "# - 示例3（中性）：\n",
    "# 新闻文本：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\n",
    "# 情绪词典：free:0.2,immateriality:-0.2\n",
    "# 输出:<think>语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响。此外，新闻文本中“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。</think> {\"情绪得分\":\"0\"}\n",
    "\n",
    "# - 示例4（比较消极）：\n",
    "# 新闻文本：我们投入的前期费用谁来承担\n",
    "# 情绪词典：invest:0.3\n",
    "# 输出:<think>语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪。新闻文本中“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。</think> {\"情绪得分\":\"-0.5\"}\n",
    "\n",
    "# - 示例5（消极）：\n",
    "# 新闻文本：饱受美国次贷危机冲击的华尔街再次风云突变\n",
    "# 情绪词典：crash:-0.9,meltdown:-0.8\n",
    "# 输出:<think>语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分，符合-1的情绪评分。</think> {\"情绪得分\":\"-1\"}\n",
    "\n",
    "\n",
    "# **输出规范**\n",
    "# - 五档制强制选择\n",
    "# - 输出格式：{\"情绪得分\":\"...\"}\n",
    "\n",
    "# 现在请你开始进行分析，严格按照输出规范输出结果，情绪词典分值仅作语义方向参考：\n",
    "# 新闻文本：{cut_news}\n",
    "# 情绪词典：{sentiment_dict_v2}\"\"\"\n",
    "    \n",
    "#     # 使用批处理加速推理并支持重试逻辑\n",
    "#     processed_df = process_dataframe(df, prompt_template, batch_size=48, max_retries=3)\n",
    "    \n",
    "#     # 保存结果\n",
    "#     processed_df.to_csv(\"processed_data_with_retries.csv\", index=False,encoding = 'utf_8_sig')\n",
    "    \n",
    "#     # 分析成功率\n",
    "#     success_count = len(processed_df[processed_df['findal_score'].apply(lambda x: isinstance(x, float))])\n",
    "#     print(f\"成功率: {success_count}/{len(processed_df)} ({success_count/len(processed_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd942fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备批处理数据...\n",
      "开始处理 500 条数据，共 16 个批次...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [57:22<00:00, 215.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2轮重试: 处理 193 条数据，共 7 个批次...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/root/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.19999999999999998` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "  0%|          | 0/7 [19:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 281\u001b[0m\n\u001b[1;32m    233\u001b[0m     prompt_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m**角色定义**\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124m擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分，请思考后回答。\u001b[39m\n\u001b[1;32m    235\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124m新闻文本：\u001b[39m\u001b[38;5;132;01m{cut_news}\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124m情绪词典：\u001b[39m\u001b[38;5;132;01m{sentiment_dict_v2}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# 使用批处理加速推理\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_process_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# 保存结果\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     processed_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_data_batched.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 174\u001b[0m, in \u001b[0;36mbatch_process_dataframe\u001b[0;34m(df, prompt_template, batch_size, max_retries)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# 单独处理每个样本，降低批处理中的干扰\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_indices, batch_prompts):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# 使用原始predict函数进行重试\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlhl_ds_output\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m response\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# 提取情绪得分\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(prompt, temperature, max_length, return_full)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 生成回答\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.03\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 解码输出\u001b[39;00m\n\u001b[1;32m     43\u001b[0m full_response \u001b[38;5;241m=\u001b[39m global_tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/utils.py:2465\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2458\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2459\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2460\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2461\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/utils.py:3434\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3434\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3438\u001b[0m     outputs,\n\u001b[1;32m   3439\u001b[0m     model_kwargs,\n\u001b[1;32m   3440\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    819\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:549\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    538\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    539\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m         position_embeddings,\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:262\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:169\u001b[0m, in \u001b[0;36mQwen2Attention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    168\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 169\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:92\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m     90\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m     91\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[0;32m---> 92\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m     93\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:67\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     65\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     66\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m :]\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def batch_process_dataframe(df, prompt_template, batch_size=4, max_retries=3):\n",
    "    \"\"\"\n",
    "    使用批处理方式处理DataFrame，提高GPU利用率\n",
    "    \n",
    "    参数:\n",
    "        df: 输入的DataFrame\n",
    "        prompt_template: 包含{cut_news}和{sentiment_dict_v2}占位符的模板\n",
    "        batch_size: 批处理大小，默认为4\n",
    "        max_retries: 最大重试次数，默认为3\n",
    "        \n",
    "    返回:\n",
    "        处理后的DataFrame，包含预测结果和提取的分数\n",
    "    \"\"\"\n",
    "    global global_model, global_tokenizer\n",
    "    \n",
    "    # 检查模型是否已加载\n",
    "    if global_model is None or global_tokenizer is None:\n",
    "        load_model()\n",
    "    \n",
    "    # 添加结果列\n",
    "    if 'lhl_ds_output' not in df.columns:\n",
    "        df['lhl_ds_output'] = None\n",
    "    if 'findal_score' not in df.columns:\n",
    "        df['findal_score'] = None\n",
    "    if 'retry_count' not in df.columns:\n",
    "        df['retry_count'] = 0\n",
    "    \n",
    "    # 定义正则表达式模式，用于提取情绪得分\n",
    "    score_pattern = r'{\"情绪得分\"\\s*:\\s*\"([^\"]+)\"}'\n",
    "    \n",
    "    # 初始化索引列表和对应的提示词列表\n",
    "    all_indices = []\n",
    "    all_prompts = []\n",
    "    \n",
    "    # 准备所有需要处理的数据\n",
    "    print(\"准备批处理数据...\")\n",
    "    for idx in range(len(df)):\n",
    "        if pd.isna(df.at[idx, 'findal_score']) and df.at[idx, 'retry_count'] < max_retries:\n",
    "            row = df.iloc[idx]\n",
    "            current_prompt = prompt_template.replace(\"{cut_news}\", str(row['cut_news'])).replace(\"{sentiment_dict_v2}\", str(row['sentiment_dict_v2']))\n",
    "            all_indices.append(idx)\n",
    "            all_prompts.append(current_prompt)\n",
    "    \n",
    "    # 如果没有需要处理的数据，直接返回\n",
    "    if not all_indices:\n",
    "        print(\"没有需要处理的数据\")\n",
    "        return df\n",
    "    \n",
    "    # 批量处理函数\n",
    "    def batch_predict(indices, prompts):\n",
    "        # 格式化所有提示词\n",
    "        formatted_prompts = [f\"指令: {p}\\n\\n输出: \" for p in prompts]\n",
    "        \n",
    "        # 编码所有输入\n",
    "        inputs = global_tokenizer(\n",
    "            formatted_prompts,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=2048  # 输入文本最大长度\n",
    "        ).to(global_model.device)\n",
    "        \n",
    "        # 批量生成\n",
    "        with torch.no_grad():\n",
    "            outputs = global_model.generate(\n",
    "                inputs.input_ids,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                max_length=4096,\n",
    "                temperature=0.1,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=global_tokenizer.pad_token_id,\n",
    "                repetition_penalty=1.03,\n",
    "                eos_token_id=global_tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # 解码所有输出\n",
    "        full_responses = [global_tokenizer.decode(output, skip_special_tokens=False) for output in outputs]\n",
    "        \n",
    "        # 提取实际响应部分\n",
    "        responses = [response.split(\"输出: \")[-1] for response in full_responses]\n",
    "        \n",
    "        return responses\n",
    "    \n",
    "    # 计算需要处理的批次数\n",
    "    total_batches = (len(all_indices) + batch_size - 1) // batch_size\n",
    "    \n",
    "    # 首次批量处理所有数据\n",
    "    print(f\"开始处理 {len(all_indices)} 条数据，共 {total_batches} 个批次...\")\n",
    "    processed_count = 0\n",
    "    \n",
    "    for i in tqdm(range(0, len(all_indices), batch_size)):\n",
    "        batch_indices = all_indices[i:i+batch_size]\n",
    "        batch_prompts = all_prompts[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            # 批量预测\n",
    "            batch_responses = batch_predict(batch_indices, batch_prompts)\n",
    "            \n",
    "            # 处理预测结果\n",
    "            for idx, response in zip(batch_indices, batch_responses):\n",
    "                df.at[idx, 'lhl_ds_output'] = response\n",
    "                \n",
    "                # 提取情绪得分\n",
    "                match = re.search(score_pattern, response)\n",
    "                if match:\n",
    "                    score_str = match.group(1)\n",
    "                    try:\n",
    "                        # 尝试转换为浮点数\n",
    "                        score = float(score_str)\n",
    "                        # 验证分数是否在有效范围内\n",
    "                        if score in [-1.0, -0.5, 0.0, 0.5, 1.0]:\n",
    "                            df.at[idx, 'findal_score'] = score\n",
    "                            processed_count += 1\n",
    "                        else:\n",
    "                            # 无效分数，记录重试次数\n",
    "                            df.at[idx, 'retry_count'] += 1\n",
    "                    except ValueError:\n",
    "                        # 无法转换为浮点数，记录重试次数\n",
    "                        df.at[idx, 'retry_count'] += 1\n",
    "                else:\n",
    "                    # 未找到匹配，记录重试次数\n",
    "                    df.at[idx, 'retry_count'] += 1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"处理批次出错: {str(e)}\")\n",
    "            # 标记批次中的所有样本需要重试\n",
    "            for idx in batch_indices:\n",
    "                df.at[idx, 'retry_count'] += 1\n",
    "                df.at[idx, 'lhl_ds_output'] = f\"ERROR: {str(e)}\"\n",
    "        \n",
    "        # 每批次后清理GPU缓存\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # 处理需要重试的数据\n",
    "    retry_round = 1\n",
    "    while retry_round < max_retries:\n",
    "        # 收集需要重试的样本\n",
    "        retry_indices = []\n",
    "        retry_prompts = []\n",
    "        \n",
    "        for idx in range(len(df)):\n",
    "            if pd.isna(df.at[idx, 'findal_score']) and df.at[idx, 'retry_count'] == retry_round:\n",
    "                row = df.iloc[idx]\n",
    "                # 为重试添加额外提示\n",
    "                retry_prompt = prompt_template.replace(\"{cut_news}\", str(row['cut_news'])).replace(\"{sentiment_dict_v2}\", str(row['sentiment_dict_v2']))\n",
    "                \n",
    "                retry_indices.append(idx)\n",
    "                retry_prompts.append(retry_prompt)\n",
    "        \n",
    "        if not retry_indices:\n",
    "            break\n",
    "            \n",
    "        # 计算重试批次数\n",
    "        retry_batches = (len(retry_indices) + batch_size - 1) // batch_size\n",
    "        print(f\"第{retry_round+1}轮重试: 处理 {len(retry_indices)} 条数据，共 {retry_batches} 个批次...\")\n",
    "        \n",
    "        for i in tqdm(range(0, len(retry_indices), batch_size)):\n",
    "            batch_indices = retry_indices[i:i+batch_size]\n",
    "            batch_prompts = retry_prompts[i:i+batch_size]\n",
    "            \n",
    "            try:\n",
    "                # 重试时使用更低的温度\n",
    "                temperature = max(0.1, 0.3 - 0.1 * retry_round)\n",
    "                \n",
    "                # 单独处理每个样本，降低批处理中的干扰\n",
    "                for idx, prompt in zip(batch_indices, batch_prompts):\n",
    "                    # 使用原始predict函数进行重试\n",
    "                    response = predict(prompt, temperature=temperature)\n",
    "                    df.at[idx, 'lhl_ds_output'] = response\n",
    "                    \n",
    "                    # 提取情绪得分\n",
    "                    match = re.search(score_pattern, response)\n",
    "                    if match:\n",
    "                        score_str = match.group(1)\n",
    "                        try:\n",
    "                            score = float(score_str)\n",
    "                            if score in [-1.0, -0.5, 0.0, 0.5, 1.0]:\n",
    "                                df.at[idx, 'findal_score'] = score\n",
    "                                processed_count += 1\n",
    "                            else:\n",
    "                                df.at[idx, 'retry_count'] += 1\n",
    "                        except ValueError:\n",
    "                            df.at[idx, 'retry_count'] += 1\n",
    "                    else:\n",
    "                        df.at[idx, 'retry_count'] += 1\n",
    "                    \n",
    "                    # 每次处理后清理GPU缓存\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"重试批次出错: {str(e)}\")\n",
    "                for idx in batch_indices:\n",
    "                    df.at[idx, 'retry_count'] += 1\n",
    "                    df.at[idx, 'lhl_ds_output'] = f\"ERROR in retry {retry_round+1}: {str(e)}\"\n",
    "                \n",
    "                # 出错后清理GPU缓存\n",
    "                torch.cuda.empty_cache()\n",
    "                time.sleep(1)  # 出错后稍作等待\n",
    "        \n",
    "        retry_round += 1\n",
    "    \n",
    "    # 标记最终仍无法提取分数的行\n",
    "    for idx in range(len(df)):\n",
    "        if pd.isna(df.at[idx, 'findal_score']) and df.at[idx, 'retry_count'] >= max_retries:\n",
    "            df.at[idx, 'findal_score'] = 'FAILED_AFTER_RETRIES'\n",
    "    \n",
    "    # 统计成功率\n",
    "    success_count = len(df[df['findal_score'].apply(lambda x: isinstance(x, float))])\n",
    "    print(f\"处理完成！成功率: {success_count}/{len(df)} ({success_count/len(df)*100:.2f}%)\")\n",
    "    print(f\"平均重试次数: {df['retry_count'].mean():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 确保已经导入必要的库和定义了predict函数\n",
    "    # import torch\n",
    "    # from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    \n",
    "    # 加载模型（仅需一次）\n",
    "    # load_model()\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_csv(\"/root/LLM_news_emo_analyze/wxy_use/deepseek_test_500_wxy_0420.csv\", encoding='utf_8_sig', lineterminator='\\n')\n",
    "    \n",
    "    # 设置prompt模板\n",
    "    prompt_template = \"\"\"**角色定义**\n",
    "擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分，请思考后回答。\n",
    "\n",
    "**核心任务**\n",
    "1. 分析新闻整体内容情绪\n",
    "2. 匹配情绪词典关键词\n",
    "3. 五档制评分（-1/-0.5/0/0.5/1）\n",
    "\n",
    "**评分逻辑**\n",
    "1. 语义匹配：忽略偏离词汇，保留有效情绪词\n",
    "2. 评分验证：整体语义优先，情绪词辅助修正\n",
    "\n",
    "**示例说明**\n",
    "- 示例1（积极）：\n",
    "新闻文本：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\n",
    "情绪词典：profitability:0.6,profit:0.8\n",
    "输出:<think>语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破。“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。</think> {\"情绪得分\":\"1\"}\n",
    "\n",
    "- 示例2（比较积极）：\n",
    "新闻文本：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\n",
    "情绪词典：mispricing:-0.4,advantage:0.7\n",
    "输出:<think>语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号。此外，新闻文本未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。</think> {\"情绪得分\":\"0.5\"}\n",
    "\n",
    "- 示例3（中性）：\n",
    "新闻文本：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\n",
    "情绪词典：free:0.2,immateriality:-0.2\n",
    "输出:<think>语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响。此外，新闻文本中“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。</think> {\"情绪得分\":\"0\"}\n",
    "\n",
    "- 示例4（比较消极）：\n",
    "新闻文本：我们投入的前期费用谁来承担\n",
    "情绪词典：invest:0.3\n",
    "输出:<think>语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪。新闻文本中“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。</think> {\"情绪得分\":\"-0.5\"}\n",
    "\n",
    "- 示例5（消极）：\n",
    "新闻文本：饱受美国次贷危机冲击的华尔街再次风云突变\n",
    "情绪词典：crash:-0.9,meltdown:-0.8\n",
    "输出:<think>语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分，符合-1的情绪评分。</think> {\"情绪得分\":\"-1\"}\n",
    "\n",
    "\n",
    "**输出规范**\n",
    "- 五档制强制选择\n",
    "- 输出格式：{\"情绪得分\":\"...\"}\n",
    "\n",
    "现在请你开始进行分析，严格按照输出规范输出结果，情绪词典分值仅作语义方向参考：\n",
    "新闻文本：{cut_news}\n",
    "情绪词典：{sentiment_dict_v2}\"\"\"\n",
    "    \n",
    "    # 使用批处理加速推理\n",
    "    processed_df = batch_process_dataframe(df, prompt_template, batch_size=32, max_retries=3)\n",
    "    \n",
    "    # 保存结果\n",
    "    processed_df.to_csv(\"processed_data_batched.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6cf01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv(\"processed_data_batched.csv\", index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc01a471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除了 2 行\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 记录删除前的行数\n",
    "original_rows = len(processed_df)\n",
    "\n",
    "# 删除 findal_score 列的值是 FAILED_AFTER_RETRIES 的行\n",
    "processed_df2 = processed_df[processed_df['findal_score'] != 'FAILED_AFTER_RETRIES']\n",
    "\n",
    "# 记录删除后的行数\n",
    "remaining_rows = len(processed_df2)\n",
    "\n",
    "# 计算删除的行数\n",
    "deleted_rows = original_rows - remaining_rows\n",
    "\n",
    "print(f\"删除了 {deleted_rows} 行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4fd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0647a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['findal_score'] 的数值分布： 人工标注\n",
      " 0.0    190\n",
      " 0.5    158\n",
      "-0.5     80\n",
      "-1.0     46\n",
      " 1.0     23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = processed_df2['人工标注'].value_counts()\n",
    "print(\"df['findal_score'] 的数值分布：\",value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56088d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findal_score与deepseek的一致率: 0.40562248995983935\n",
      "findal_score与人工标注的一致率: 0.40562248995983935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7352/558342751.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(float)\n",
      "/tmp/ipykernel_7352/558342751.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(float)\n",
      "/tmp/ipykernel_7352/558342751.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 统一列数据类型为浮点数\n",
    "def unify_column_types(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 计算两列的一致率\n",
    "def calculate_consistency_rate(col1, col2):\n",
    "    same_count = (col1 == col2).sum()\n",
    "    total_count = len(col1)\n",
    "    return same_count / total_count if total_count > 0 else 0\n",
    "\n",
    "columns_to_convert = ['deepseek', 'findal_score', '人工标注']\n",
    "# 统一数据类型\n",
    "processed_df2 = unify_column_types(processed_df2, columns_to_convert)\n",
    "\n",
    "# 计算findal_score与deepseek的一致率\n",
    "consistency_rate_1 = calculate_consistency_rate(processed_df2['findal_score'], processed_df2['deepseek'])\n",
    "print(f\"findal_score与deepseek的一致率: {consistency_rate_1}\")\n",
    "\n",
    "# 计算findal_score与人工标注的一致率\n",
    "consistency_rate_2 = calculate_consistency_rate(processed_df2['findal_score'], processed_df2['人工标注'])\n",
    "print(f\"findal_score与人工标注的一致率: {consistency_rate_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7dbdc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('ouutput2.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e26e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def process_dataframe(df, prompt_template, batch_size=1):\n",
    "#     \"\"\"\n",
    "#     处理DataFrame，为每行生成预测并提取分数\n",
    "    \n",
    "#     参数:\n",
    "#         df: 输入的DataFrame\n",
    "#         prompt_template: 包含{cut_news}和{sentiment_dict_v2}占位符的模板\n",
    "#         batch_size: 每次处理的批次大小，默认为1\n",
    "        \n",
    "#     返回:\n",
    "#         处理后的DataFrame，包含预测结果和提取的分数\n",
    "#     \"\"\"\n",
    "#     # 添加结果列\n",
    "#     if 'lhl_ds_output' not in df.columns:\n",
    "#         df['lhl_ds_output'] = None\n",
    "#     if 'findal_score' not in df.columns:\n",
    "#         df['findal_score'] = None\n",
    "    \n",
    "#     # 定义正则表达式模式，用于提取情绪得分\n",
    "#     score_pattern = r'{\"情绪得分\"\\s*:\\s*\"([^\"]+)\"}'\n",
    "    \n",
    "#     # 创建进度条\n",
    "#     total_rows = len(df)\n",
    "#     print(f\"开始处理 {total_rows} 行数据...\")\n",
    "    \n",
    "#     # 使用tqdm显示进度\n",
    "#     for i in tqdm(range(total_rows)):\n",
    "#         row = df.iloc[i]\n",
    "        \n",
    "#         try:\n",
    "#             # 替换模板中的占位符\n",
    "#             current_prompt = prompt_template.replace(\"{cut_news}\", str(row['cut_news'])).replace(\"{sentiment_dict_v2}\", str(row['sentiment_dict_v2']))\n",
    "            \n",
    "#             # 调用预测函数\n",
    "#             prediction = predict(current_prompt, temperature=0.3)  # 降低温度以增加确定性\n",
    "            \n",
    "#             # 保存完整输出\n",
    "#             df.at[i, 'lhl_ds_output'] = prediction\n",
    "            \n",
    "#             # 提取情绪得分\n",
    "#             match = re.search(score_pattern, prediction)\n",
    "#             if match:\n",
    "#                 score_str = match.group(1)\n",
    "#                 try:\n",
    "#                     # 尝试转换为浮点数\n",
    "#                     score = float(score_str)\n",
    "#                     df.at[i, 'findal_score'] = score\n",
    "#                 except ValueError:\n",
    "#                     # 如果无法转换为浮点数，保留原始字符串\n",
    "#                     df.at[i, 'findal_score'] = score_str\n",
    "#             else:\n",
    "#                 df.at[i, 'findal_score'] = None\n",
    "                \n",
    "#             # 每批次处理完成后清理CUDA缓存\n",
    "#             if (i + 1) % batch_size == 0:\n",
    "#                 torch.cuda.empty_cache()\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"处理第 {i} 行时出错: {str(e)}\")\n",
    "#             df.at[i, 'lhl_ds_output'] = f\"ERROR: {str(e)}\"\n",
    "#             df.at[i, 'findal_score'] = None\n",
    "            \n",
    "#             # 错误后清理CUDA缓存\n",
    "#             torch.cuda.empty_cache()\n",
    "            \n",
    "#             # 出错后暂停短暂时间，让GPU冷却\n",
    "#             time.sleep(1)\n",
    "    \n",
    "#     print(\"处理完成！\")\n",
    "#     return df\n",
    "\n",
    "# # 使用示例\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 加载模型（仅需一次）\n",
    "#     load_model()\n",
    "    \n",
    "#     # 读取数据\n",
    "#     df = pd.read_csv(\"your_data.csv\")\n",
    "    \n",
    "#     # 设置prompt模板\n",
    "#     prompt_template = \"\"\"\n",
    "#     **角色定义**\n",
    "#     擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分：\n",
    "#     以下是新闻文本：\n",
    "#     <新闻文本>\n",
    "#     {cut_news}\n",
    "#     </新闻文本>\n",
    "\n",
    "#     以下是情绪词典：\n",
    "#     <情绪词典>\n",
    "#     {sentiment_dict_v2}\n",
    "#     </情绪词典>\n",
    "\n",
    "#     **核心任务**\n",
    "#     1. 分析新闻整体内容情绪\n",
    "#     2. 匹配情绪词典关键词\n",
    "#     3. 五档制评分（-1/-0.5/0/0.5/1）\n",
    "\n",
    "#     **评分逻辑**\n",
    "#     1. 语义匹配：忽略偏离词汇，保留有效情绪词\n",
    "#     2. 评分验证：整体语义优先，情绪词辅助修正\n",
    "\n",
    "#     **输出规范**\n",
    "#     - 五档制强制选择\n",
    "#     - 格式：{\"情绪得分\":\"...\"}\n",
    "\n",
    "#     （情绪词典分值仅作语义方向参考）\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 处理数据\n",
    "#     processed_df = process_dataframe(df, prompt_template, batch_size=5)\n",
    "    \n",
    "#     # 保存结果\n",
    "#     processed_df.to_csv(\"processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42cc24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e8689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e960ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a55d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a18b2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6283a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a05def5",
   "metadata": {},
   "source": [
    "### **wxy测试用，记得改prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bb7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <｜begin▁of▁sentence｜>\n",
      "**角色定义**\n",
      "擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分：\n",
      "以下是新闻文本：\n",
      "<新闻文本>\n",
      "也有券商迅速发声，大有代替比亚迪“辟谣”之势\n",
      "</新闻文本>\n",
      "\n",
      "以下是情绪词典：\n",
      "</情绪词典>\n",
      "assertable:0.2, presumptively:0.0\n",
      "</情绪词典>\n",
      "\n",
      "**核心任务**\n",
      "1. 分析新闻整体内容情绪\n",
      "2. 匹配情绪词典关键词\n",
      "3. 五档制评分（-1/-0.5/0/0.5/1）\n",
      "\n",
      "**评分逻辑**\n",
      "1. 语义匹配：忽略偏离词汇，保留有效情绪词\n",
      "2. 评分验证：整体语义优先，情绪词辅助修正\n",
      "\n",
      "**精简示例**\n",
      "示例1（积极）：\n",
      "新闻：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\n",
      "情绪词：profitability:0.6,profit:0.8\n",
      "理由:①语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破；②关键情绪词验证：“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。\n",
      "情绪得分:1\n",
      "\n",
      "示例2（比较积极）：\n",
      "新闻：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\n",
      "情绪词：mispricing:-0.4,advantage:0.7\n",
      "理由:①语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号；②关键情绪词验证：未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。\n",
      "情绪得分:0.5\n",
      "\n",
      "示例3（中性）：\n",
      "新闻：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\n",
      "情绪词：free:0.2,immateriality:-0.2\n",
      "理由:①语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响；②关键情绪词验证：“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。\n",
      "情绪得分:0\n",
      "\n",
      "示例4（比较消极）：\n",
      "新闻：我们投入的前期费用谁来承担\n",
      "情绪词：invest:0.3\n",
      "理由:①语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪；②关键情绪词验证：“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。\n",
      "情绪得分:-0.5\n",
      "\n",
      "示例5（消极）：\n",
      "新闻：饱受美国次贷危机冲击的华尔街再次风云突变\n",
      "情绪词：crash:-0.9,meltdown:-0.8\n",
      "理由:①语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分。\n",
      "情绪得分:-1\n",
      "\n",
      "\n",
      "**输出规范**\n",
      "- 五档制强制选择\n",
      "- 格式：{\"情绪得分\":\"...\"}\n",
      "\n",
      "\n",
      "（情绪词典分值仅作语义方向参考）\n",
      "<think>好的，我需要分析这条新闻的情绪得分。首先，新闻内容是“也有券商迅速发声，大有代替比亚迪‘辟谣’之势。” 这里的关键点在于券商迅速介入并迅速辟谣。\n",
      "\n",
      "接下来看情绪词典中的关键词，有assertable（0.2）和presumptively（0.0）。新闻中的“迅速”可能对应assertable，但其分数是0.2，属于中性偏积极。而“辟谣”中的“辟”可能对应presumptively，但分值是0.0，中性。\n",
      "\n",
      "根据评分逻辑，整体语义优先，情绪词辅助修正。新闻中“迅速辟谣”整体传达出信息量大、迅速的事件，带有积极的意味，但情绪词的辅助需要确认。但“迅速”可能对应assertable的中性部分，而“辟谣”中的“辟”可能对应presumptively的中性，所以情绪词的整体贡献可能中性。\n",
      "\n",
      "不过，新闻中还有“大有代替”这样的表述，可能暗示对比亚迪的取代行为，但取代通常有负面意义，但这里用了“大有代替”，可能隐含积极的策略，比如质疑或质疑。\n",
      "\n",
      "综合来看，整体语义偏向积极，但情绪词的辅助可能中性，但“大有代替”可能带有负面情绪，但因为用了“大有”可能暗示积极的策略，所以可能整体情绪中性，但分值低。\n",
      "\n",
      "不过，情绪词典中assertable是0.2，presumptively是0.0，而新闻中的“迅速辟谣”可能对应assertable的中性部分，而“辟谣”中的“辟”对应presumptively的中性，但整体情绪可能偏向积极，但情绪词的辅助可能中性，所以可能评分在中性偏积极。\n",
      "\n",
      "不过，可能更倾向于积极，因为“迅速辟谣”可能暗示快速纠正问题，但“大有代替”可能暗示竞争加剧，但“代替”本身可能有负面情绪，但用了“大有”可能暗示积极的策略。\n",
      "\n",
      "但情绪词典中没有直接匹配的词，所以可能需要结合整体语义和情绪词的匹配。整体情绪偏向积极，但情绪词词典中的积极词分值较低，可能评分中性偏积极。\n",
      "\n",
      "不过，根据示例，比较积极的新闻评分是0.5，而这里可能更偏向积极，但情绪词词典中的积极词分值较低，所以可能评分是0.5。\n",
      "\n",
      "不过，仔细分析，新闻中的“迅速辟谣”可能暗示快速纠正问题，但“大有代替”可能暗示竞争加剧，但“代替”本身可能有负面情绪，但用了“大有”可能暗示积极的策略，所以可能评分是积极，但情绪词词典中的积极词分值较低，可能评分是0.5。\n",
      "\n",
      "但更准确的分析是，新闻整体传达积极的信息，特别是“迅速辟谣”和“大有代替”，但情绪词词典中的积极词分值较低，可能评分是0.5。\n",
      "\n",
      "不过，可能更接近积极，因为“迅速辟谣”暗示快速纠正问题，而“大有代替”可能暗示竞争加剧，但竞争加剧可能有负面情绪，但“代替”本身可能有负面情绪，但用了“大有”可能暗示积极的策略，所以可能评分是积极。\n",
      "\n",
      "不过，情绪词典中的“assertable”是0.2，属于中性偏积极，而“presumptively”是0.0，中性，但新闻中的“迅速辟谣”可能对应assertable的中性部分，而“辟谣”中的“辟”对应presumptively的中性，但情绪词的辅助可能需要调整，整体情绪可能偏向积极，但评分可能中性偏积极。\n",
      "\n",
      "综合考虑，情绪得分可能是0.5。\n",
      "</think>\n",
      "\n",
      "{\"情绪得分\":\"0.5\"}<｜end▁of▁sentence｜>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \n",
    "    \"\"\"\n",
    "    <｜begin▁of▁sentence｜>\\n**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分：\\n以下是新闻文本：\\n<新闻文本>\\n也有券商迅速发声，大有代替比亚迪“辟谣”之势\\n</新闻文本>\\n\\n以下是情绪词典：\\n</情绪词典>\\nassertable:0.2, presumptively:0.0\\n</情绪词典>\\n\\n**核心任务**\\n1. 分析新闻整体内容情绪\\n2. 匹配情绪词典关键词\\n3. 五档制评分（-1/-0.5/0/0.5/1）\\n\\n**评分逻辑**\\n1. 语义匹配：忽略偏离词汇，保留有效情绪词\\n2. 评分验证：整体语义优先，情绪词辅助修正\\n\\n**精简示例**\\n示例1（积极）：\\n新闻：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\\n情绪词：profitability:0.6,profit:0.8\\n理由:①语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破；②关键情绪词验证：“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。\\n情绪得分:1\\n\\n示例2（比较积极）：\\n新闻：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\\n情绪词：mispricing:-0.4,advantage:0.7\\n理由:①语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号；②关键情绪词验证：未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。\\n情绪得分:0.5\\n\\n示例3（中性）：\\n新闻：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\\n情绪词：free:0.2,immateriality:-0.2\\n理由:①语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响；②关键情绪词验证：“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。\\n情绪得分:0\\n\\n示例4（比较消极）：\\n新闻：我们投入的前期费用谁来承担\\n情绪词：invest:0.3\\n理由:①语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪；②关键情绪词验证：“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。\\n情绪得分:-0.5\\n\\n示例5（消极）：\\n新闻：饱受美国次贷危机冲击的华尔街再次风云突变\\n情绪词：crash:-0.9,meltdown:-0.8\\n理由:①语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分。\\n情绪得分:-1\\n\\n\\n**输出规范**\\n- 五档制强制选择\\n- 格式：{\"情绪得分\":\"...\"}\\n\\n\\n（情绪词典分值仅作语义方向参考）\\n<think>好的，我需要分析这条新闻的情绪得分。首先，新闻内容是“也有券商迅速发声，大有代替比亚迪‘辟谣’之势。” 这里的关键点在于券商迅速介入并迅速辟谣。\\n\\n接下来看情绪词典中的关键词，有assertable（0.2）和presumptively（0.0）。新闻中的“迅速”可能对应assertable，但其分数是0.2，属于中性偏积极。而“辟谣”中的“辟”可能对应presumptively，但分值是0.0，中性。\\n\\n根据评分逻辑，整体语义优先，情绪词辅助修正。新闻中“迅速辟谣”整体传达出信息量大、迅速的事件，带有积极的意味，但情绪词的辅助需要确认。但“迅速”可能对应assertable的中性部分，而“辟谣”中的“辟”可能对应presumptively的中性，所以情绪词的整体贡献可能中性。\\n\\n不过，新闻中还有“大有代替”这样的表述，可能暗示对比亚迪的取代行为，但取代通常有负面意义，但这里用了“大有代替”，可能隐含积极的策略，比如质疑或质疑。\\n\\n综合来看，整体语义偏向积极，但情绪词的辅助可能中性，但“大有代替”可能带有负面情绪，但因为用了“大有”可能暗示积极的策略，所以可能整体情绪中性，但分值低。\\n\\n不过，情绪词典中assertable是0.2，presumptively是0.0，而新闻中的“迅速辟谣”可能对应assertable的中性部分，而“辟谣”中的“辟”对应presumptively的中性，但整体情绪可能偏向积极，但情绪词的辅助可能中性，所以可能评分在中性偏积极。\\n\\n不过，可能更倾向于积极，因为“迅速辟谣”可能暗示快速纠正问题，但“大有代替”可能暗示竞争加剧，但“代替”本身可能有负面情绪，但用了“大有”可能暗示积极的策略。\\n\\n但情绪词典中没有直接匹配的词，所以可能需要结合整体语义和情绪词的匹配。整体情绪偏向积极，但情绪词词典中的积极词分值较低，可能评分中性偏积极。\\n\\n不过，根据示例，比较积极的新闻评分是0.5，而这里可能更偏向积极，但情绪词词典中的积极词分值较低，所以可能评分是0.5。\\n\\n不过，仔细分析，新闻中的“迅速辟谣”可能暗示快速纠正问题，但“大有代替”可能暗示竞争加剧，但“代替”本身可能有负面情绪，但用了“大有”可能暗示积极的策略，所以可能评分是积极，但情绪词词典中的积极词分值较低，可能评分是0.5。\\n\\n但更准确的分析是，新闻整体传达积极的信息，特别是“迅速辟谣”和“大有代替”，但情绪词词典中的积极词分值较低，可能评分是0.5。\\n\\n不过，可能更接近积极，因为“迅速辟谣”暗示快速纠正问题，而“大有代替”可能暗示竞争加剧，但竞争加剧可能有负面情绪，但“代替”本身可能有负面情绪，但用了“大有”可能暗示积极的策略，所以可能评分是积极。\\n\\n不过，情绪词典中的“assertable”是0.2，属于中性偏积极，而“presumptively”是0.0，中性，但新闻中的“迅速辟谣”可能对应assertable的中性部分，而“辟谣”中的“辟”对应presumptively的中性，但情绪词的辅助可能需要调整，整体情绪可能偏向积极，但评分可能中性偏积极。\\n\\n综合考虑，情绪得分可能是0.5。\\n</think>\\n\\n{\"情绪得分\":\"0.5\"}<｜end▁of▁sentence｜>\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ef95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 读取CSV文件（需替换为实际路径）\n",
    "csv_path = \"/root/LLM_news_emo_analyze/wxy_use/LLM_test_500_wxy.csv\"  # 替换为真实文件路径\n",
    "#test_500 = pd.read_csv(csv_path,encoding = 'utf 8 sig',lineterminator= '\\n')\n",
    "test_500 = pd.read_csv(csv_path)\n",
    "#测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_7 = test_500.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"**角色定义**\n",
    "擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分。\n",
    "\n",
    "**核心任务**\n",
    "1. 分析新闻整体内容情绪\n",
    "2. 匹配情绪词典关键词\n",
    "3. 五档制评分（-1/-0.5/0/0.5/1）\n",
    "\n",
    "**评分逻辑**\n",
    "1. 语义匹配：忽略偏离词汇，保留有效情绪词\n",
    "2. 评分验证：整体语义优先，情绪词辅助修正\n",
    "\n",
    "**示例说明**\n",
    "- 示例1（积极）：\n",
    "新闻文本：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\n",
    "情绪词典：profitability:0.6,profit:0.8\n",
    "输出:<think>语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破。“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。</think> {\"情绪得分\":\"1\"}\n",
    "\n",
    "- 示例2（比较积极）：\n",
    "新闻文本：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\n",
    "情绪词典：mispricing:-0.4,advantage:0.7\n",
    "输出:<think>语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号。此外，新闻文本未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。</think> {\"情绪得分\":\"0.5\"}\n",
    "\n",
    "- 示例3（中性）：\n",
    "新闻文本：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\n",
    "情绪词典：free:0.2,immateriality:-0.2\n",
    "输出:<think>语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响。此外，新闻文本中“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。</think> {\"情绪得分\":\"0\"}\n",
    "\n",
    "- 示例4（比较消极）：\n",
    "新闻文本：我们投入的前期费用谁来承担\n",
    "情绪词典：invest:0.3\n",
    "输出:<think>语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪。新闻文本中“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。</think> {\"情绪得分\":\"-0.5\"}\n",
    "\n",
    "- 示例5（消极）：\n",
    "新闻文本：饱受美国次贷危机冲击的华尔街再次风云突变\n",
    "情绪词典：crash:-0.9,meltdown:-0.8\n",
    "输出:<think>语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分，符合-1的情绪评分。</think> {\"情绪得分\":\"-1\"}\n",
    "\n",
    "\n",
    "**输出规范**\n",
    "- 五档制强制选择\n",
    "- 输出格式：{\"情绪得分\":\"...\"}\n",
    "\n",
    "现在请你开始进行分析，严格按照输出规范输出结果，情绪词典分值仅作语义方向参考：\n",
    "新闻文本：{cut_news}\n",
    "情绪词典：{sentiment_dict_v2}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288af6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28718/2677121740.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_7['FTdeepseek_output'] = None\n",
      "处理进度: 100%|██████████| 16/16 [09:00<00:00, 33.75s/行]\n"
     ]
    }
   ],
   "source": [
    "test_7['FTdeepseek_output'] = None\n",
    "for index, row in tqdm(test_7.iterrows(), total=test_7.shape[0], desc=\"处理进度\", unit=\"行\"):\n",
    "    current_cut_news = row['cut_news']\n",
    "    current_sentiment_dict_v2 = row['sentiment_dict_v2']\n",
    "    # 使用 replace 方法替换占位符\n",
    "    filled_prompt = prompt.replace(\"{cut_news}\", current_cut_news).replace(\"{sentiment_dict_v2}\", current_sentiment_dict_v2)\n",
    "    emotion_score = predict(filled_prompt, return_full=True)\n",
    "    test_7.at[index, 'FTdeepseek_output'] = emotion_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>好的，我需要分析这段新闻文本的情绪，并给出五档制评分。首先，看看新闻内容：“理论上，市场的过度竞争会导致所有参与者利润不断趋近于零，而生存的本能欲望，极易导致‘经营失德’。” 这里主要讨论的是过度竞争带来的问题，特别是企业经营失德。\n",
      "\n",
      "接下来，检查情绪词典里的关键词。情绪词典里有mismanagement:-0.5和uncompetitive:-0.3。新闻中提到的是过度竞争导致利润趋近于零，这可能涉及竞争加剧的问题，但没有直接出现“竞争”或“失德”的关键词。不过，这里可能隐含了竞争带来的负面影响，也就是“经营失德”。\n",
      "\n",
      "然后，按照评分逻辑，先看整体语义。新闻中虽然没有明确的“竞争”或“失德”词汇，但“过度竞争”和“经营失德”都是负面情绪的迹象。整体语义偏向负面，因为竞争加剧可能导致公司失去竞争力，经营失德可能指公司不能维持正常运营。\n",
      "\n",
      "再结合情绪词典中的关键词，新闻中没有匹配的词，只是在整体语义上暗示了负面后果。因此，情绪得分应该在中性或负面方向。根据示例，中性是0，负面可能在-0.5或更低。但这里没有明显的负面情绪词，只是隐含竞争带来的负面影响，所以可能属于中性。\n",
      "\n",
      "综上所述，情绪得分应该是0。\n",
      "</think> {\"情绪得分\":\"0\"}<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(test_7['FTdeepseek_output'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97672a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度:   0%|          | 0/500 [01:29<?, ?行/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 使用 replace 方法替换占位符\u001b[39;00m\n\u001b[1;32m      6\u001b[0m filled_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{cut_news}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, current_cut_news)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{sentiment_dict_v2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, current_sentiment_dict_v2)\n\u001b[0;32m----> 7\u001b[0m emotion_score \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilled_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_full\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m test_500\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTdeepseek_output\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m emotion_score\n",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(prompt, temperature, max_length, return_full)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 生成回答\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.03\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 解码输出\u001b[39;00m\n\u001b[1;32m     43\u001b[0m full_response \u001b[38;5;241m=\u001b[39m global_tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/utils.py:2465\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2458\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2459\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2460\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2461\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/generation/utils.py:3434\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3434\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3438\u001b[0m     outputs,\n\u001b[1;32m   3439\u001b[0m     model_kwargs,\n\u001b[1;32m   3440\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    819\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:549\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    538\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    539\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m         position_embeddings,\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:262\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:186\u001b[0m, in \u001b[0;36mQwen2Attention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m attention_interface: Callable \u001b[38;5;241m=\u001b[39m eager_attention_forward\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn_implementation\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdpa\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    187\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meager attention. This warning can be removed using the argument `attn_implementation=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` when loading the model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/configuration_utils.py:210\u001b[0m, in \u001b[0;36mPretrainedConfig.__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    209\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m)[key]\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/configuration_utils.py:362\u001b[0m, in \u001b[0;36mPretrainedConfig._attn_implementation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn_implementation_internal\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepseek_sft/lib/python3.10/site-packages/transformers/configuration_utils.py:210\u001b[0m, in \u001b[0;36mPretrainedConfig.__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    209\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m)[key]\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_500['FTdeepseek_output'] = None\n",
    "for index, row in tqdm(test_500.iterrows(), total=test_500.shape[0], desc=\"处理进度\", unit=\"行\"):\n",
    "    current_cut_news = row['cut_news']\n",
    "    current_sentiment_dict_v2 = row['sentiment_dict_v2']\n",
    "    # 使用 replace 方法替换占位符\n",
    "    filled_prompt = prompt.replace(\"{cut_news}\", current_cut_news).replace(\"{sentiment_dict_v2}\", current_sentiment_dict_v2)\n",
    "    emotion_score = predict(filled_prompt, return_full=True)\n",
    "    test_500.at[index, 'FTdeepseek_output'] = emotion_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87fb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28718/2952616064.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_7['FTdeepseek_output'] = None\n",
      "GPU并行处理: 100%|██████████| 16/16 [05:58<00:00, 22.42s/样本]\n"
     ]
    }
   ],
   "source": [
    "#并行计算\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 定义处理单个项目的函数\n",
    "def process_single_item(args):\n",
    "    index, row, prompt_template = args\n",
    "    current_cut_news = row['cut_news']\n",
    "    current_sentiment_dict_v2 = row['sentiment_dict_v2']\n",
    "    filled_prompt = prompt_template.replace(\"{cut_news}\", current_cut_news).replace(\"{sentiment_dict_v2}\", current_sentiment_dict_v2)\n",
    "    emotion_score = predict(filled_prompt, return_full=True)\n",
    "    return index, emotion_score\n",
    "\n",
    "# 准备数据\n",
    "items_to_process = [(index, row, prompt) for index, row in test_7.iterrows()]\n",
    "\n",
    "# 初始化结果列\n",
    "test_7['FTdeepseek_output'] = None\n",
    "\n",
    "# 使用线程池并行处理\n",
    "# 调整max_workers数量，通常设置为2-4较为合适，避免GPU内存溢出\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    # 使用tqdm显示进度\n",
    "    results = list(tqdm(\n",
    "        executor.map(process_single_item, items_to_process),\n",
    "        total=len(items_to_process),\n",
    "        desc=\"GPU并行处理\",\n",
    "        unit=\"样本\"\n",
    "    ))\n",
    "\n",
    "# 更新结果到DataFrame\n",
    "for index, result in results:\n",
    "    test_7.at[index, 'FTdeepseek_output'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>好的，我现在需要分析这条新闻的情绪得分。首先，新闻内容是关于市场的过度竞争会导致所有参与者利润趋近于零，而生存本能欲望会导致“经营失德”。情绪词典里有“mismanagement:-0.5”和“uncompetitive:-0.3”。\n",
      "\n",
      "首先看整体语义。新闻提到过度竞争会导致利润趋近于零，这可能暗示市场竞争过猛，企业可能陷入困境，甚至可能失去生存的本能。这可能是一个负面的信号，因为过度竞争通常会导致企业亏损，市场不稳定。同时，提到“经营失德”可能意味着企业失去了经营的基本能力，进一步加剧了问题。\n",
      "\n",
      "接下来检查情绪词典中的关键词。新闻中并没有直接出现“mismanagement”或“uncompetitive”，只是提到了“过度竞争”和“经营失德”。不过，“过度竞争”可能与“mismanagement”相关，但新闻里没有明确的“mismanagement”出现。而“经营失德”更接近“uncompetitive”，因为过度竞争可能导致企业失去经营能力，这属于“uncompetitive”的范畴，对应情绪词-0.3。\n",
      "\n",
      "但是，新闻里提到的是过度竞争导致企业利润趋近于零，这可能不仅仅是竞争导致的失 Compet，也可能是企业自身的问题，比如管理不善、资源分配不均等。所以虽然没有直接的“uncompetitive”，但整体语义上，过度竞争可能暗示市场竞争过猛，导致企业陷入困境，这可能更偏向于负面情绪。\n",
      "\n",
      "另外，新闻中没有明显的积极词汇，比如“成功”、“增长”等，更多是负面的。因此，虽然情绪词典里的“uncompetitive”有影响，但新闻里没有直接匹配的词，可能需要结合整体语义来判断。\n",
      "\n",
      "综合来看，新闻中提到过度竞争导致企业利润趋近于零，这可能暗示市场竞争过猛，企业可能面临生存压力，导致企业失去经营能力，这可能属于负面情绪。但因为新闻里没有明确的“uncompetitive”出现，可能需要结合“uncompetitive”的程度。如果过度竞争导致企业无法维持正常运营，可能属于较严重的负面，但不确定是否达到“uncompetitive”的程度。\n",
      "\n",
      "不过，新闻里提到的是“经营失德”，这可能更接近“uncompetitiveness”（经营失德）这个方向，但新闻里并没有直接的匹配词。因此，可能需要结合整体语义和情绪词典的参考。\n",
      "\n",
      "所以，情绪词典里的“uncompetitive”对应-0.3，但新闻里并没有直接匹配，可能需要考虑整体语义。过度竞争可能带来更大的负面，但不确定是否达到“uncompetitiveness”的程度。因此，可能整体情绪属于中性，但考虑到过度竞争的负面影响，可能稍微偏向负面，但不确定是否达到-0.5。\n",
      "\n",
      "综上所述，情绪词得分可能是-0.4，因为虽然没有明确的“uncompetitiveness”出现，但过度竞争可能暗示市场竞争过猛，导致企业面临生存压力，这可能属于负面情绪，但不确定是否达到-0.5。\n",
      "</think>: {-0.4}<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(test_7['FTdeepseek_output'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13e04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefede8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9b8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "test_500['FTdeepseek_output'] = test_500['FTdeepseek_output'].astype(str)\n",
    "# 定义正则表达式\n",
    "pattern = r'{\"情绪得分\":\"([-+]?\\d+(?:\\.\\d+)?)\"}'\n",
    "\n",
    "# 定义提取函数\n",
    "def extract_score(text):\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "# 创建新列并保存提取结果\n",
    "test_500['FTdeepseek'] = test_500['FTdeepseek_output'].apply(extract_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 定义正则表达式\n",
    "pattern = r'{情绪得分:([-+]?\\d+(?:\\.\\d+)?)}'\n",
    "\n",
    "def extract_score(text):\n",
    "    if pd.isnull(text) or not isinstance(text, str):\n",
    "        return None\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "# 创建新列并保存提取结果\n",
    "test_500['deepseek'] = test_500['deepseekk_content'].apply(extract_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f48788",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_500.to_csv(\"/root/LLM_news_emo_analyze/wxy_use/deepseek_test_500_wxy_0420.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_7['FTdeepseek_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66903/3480445426.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_7[\"FTdeepseek_output\"] = None\n",
      "处理进度: 100%|██████████| 6/6 [03:10<00:00, 31.70s/行]\n"
     ]
    }
   ],
   "source": [
    "# 处理qwen_output列\n",
    "test_7[\"FTdeepseek_output\"] = None\n",
    "for index, row in tqdm(test_7.iterrows(), total=test_7.shape[0], desc=\"处理进度\", unit=\"行\"):\n",
    "    prompt = row[\"qwen_input\"]\n",
    "    model_response = predict(prompt)\n",
    "    test_7.at[index, \"FTdeepseek_output\"] = model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb41de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {'thinking_process': None, 'final_answer': '分）...\n",
      "Name: FTdeepseek_output, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_7[\"FTdeepseek_output\"].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666f05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8845575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv(\"/root/LLM_news_emo_analyze/wxy_use/deepseek_test_500_wxy_0415.csv\", encoding='utf_8_sig', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb8d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'thinking_process\\': \\'好的，我现在需要分析这条新闻的情绪得分。首先，新闻内容是：“以前，针对原材料价格低、企业生产规模小、铝型材巿场受塑钢冲击大的特点，把经营模式定位为薄利多销型。” \\\\n\\\\n首先，我要理解这句话的整体意思。这里在讨论过去的企业经营模式，指出原材料价格低、企业生产规模小、铝型材市场受塑钢冲击大的特点，然后将经营模式定位为薄利多销型。薄利多销通常意味着卖价较低，但利润相对较低，可能带来市场波动。\\\\n\\\\n接下来，检查情绪词典中的关键词。情绪词典里有undercuts:-0.3和undercut:-0.3。需要看看新闻中有没有这些词。\\\\n\\\\n新闻中提到“薄利多销型”，这里的“薄利”对应undercut，但“多销”是“undercut”的反义词，也就是“多销”对应undercut的正向。不过在词典里，“undercut”是-0.3，而“undercuts”是-0.3。这里句子中并没有直接出现“undercut”或“undercuts”，而是“薄利多销型”，可能只是描述经营模式，没有明确的负面词汇。\\\\n\\\\n接下来，分析整体语义。新闻提到的是过去的企业结构问题，强调薄利多销，但没有直接给出负面情绪的词汇，比如“亏本”或“亏损”。而是强调当前的市场状况，比如原材料价格低、企业生产规模小，铝型材市场受塑钢冲击大，这些可能暗示市场波动，但并没有明显的负面情绪如“亏损”或“负面竞争”。\\\\n\\\\n所以，整体来看，新闻主要是在陈述过去的问题，没有明显的负面词汇，也没有明显的积极情绪。因此，情绪得分应该在中性范围内，也就是0。\\\\n\\\\n再检查一下情绪词典的匹配。虽然没有直接出现“undercuts”或“undercut”，但“薄利多销型”可能暗示一些负面因素，但并没有明确的负面词汇。因此，整体上情绪应该是中性的。\\\\n\\\\n综上所述，新闻的情绪得分应该是0。\\', \\'final_answer\\': \\'{\"情绪得分\":\"0\"}<｜end▁of▁sentence｜>\\', \\'full_response\\': \\'<｜begin▁of▁sentence｜>\\\\n**角色定义**\\\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评分：\\\\n以下是新闻文本：\\\\n<新闻文本>\\\\n以前，针对原材料价格低、企业生产规模小、铝型材巿场受塑钢冲击大的特点，把经营模式定位为薄利多销型\\\\n</新闻文本>\\\\n\\\\n以下是情绪词典：\\\\n</情绪词典>\\\\nundercuts:-0.3, undercut:-0.3\\\\n</情绪词典>\\\\n\\\\n**核心任务**\\\\n1. 分析新闻整体内容情绪\\\\n2. 匹配情绪词典关键词\\\\n3. 五档制评分（-1/-0.5/0/0.5/1）\\\\n\\\\n**评分逻辑**\\\\n1. 语义匹配：忽略偏离词汇，保留有效情绪词\\\\n2. 评分验证：整体语义优先，情绪词辅助修正\\\\n\\\\n**精简示例**\\\\n示例1（积极）：\\\\n新闻：实现净利润同比增长137.98%，单季度的盈利规模超过中信证券成为业内第一\\\\n情绪词：profitability:0.6,profit:0.8\\\\n理由:①语义信息为净利润同比大幅增长137.98%及单季度盈利规模跃居行业第一，均体现超预期的盈利能力突破；②关键情绪词验证：“净利润”（匹配profit）和“盈利”（匹配profitability）共同强化积极方向。两重强信号叠加符合最高档1的评分逻辑。\\\\n情绪得分:1\\\\n\\\\n示例2（比较积极）：\\\\n新闻：中国的A股定位反而是比较便宜的，外资从全球定价认为我们非常有吸引力\\\\n情绪词：mispricing:-0.4,advantage:0.7\\\\n理由:①语义信息为A股估值被强调为“便宜”及外资认可其全球定价吸引力，隐含市场价值被低估的积极信号；②关键情绪词验证：未直接匹配词典中的“mispricing”或“advantage”，但“便宜”隐含定价偏离逻辑（映射mispricing方向），“有吸引力”间接呼应优势（advantage方向）。整体乐观基调符合中档评分0.5，缺乏词典强匹配项限制进一步上调空间。\\\\n情绪得分:0.5\\\\n\\\\n示例3（中性）：\\\\n新闻：美国信奉自由市场经济理念，主张靠无形的手调整经济活动\\\\n情绪词：free:0.2,immateriality:-0.2\\\\n理由:①语义信息为对美国经济理念的中性陈述，既未直接关联中国市场优劣，也未体现政策对华影响；②关键情绪词验证：“自由”（匹配free:+0.2）与“无形”（匹配immateriality:-0.2）存在方向冲突，但文本未实际使用“immateriality”原词（仅隐含“无形的手”概念），语义匹配强度不足。陈述性内容缺乏明确情绪导向，符合中性基准0。\\\\n情绪得分:0\\\\n\\\\n示例4（比较消极）：\\\\n新闻：我们投入的前期费用谁来承担\\\\n情绪词：invest:0.3\\\\n理由:①语义信息为对前期费用承担主体的质疑，隐含投入成本未被消化的潜在风险，传递财务负担不确定性的负面情绪；②关键情绪词验证：“投入”（匹配invest:+0.3）存在方向性冲突，因文本中“投入”实际指向成本分摊压力而非正向投资预期，情绪词得分被整体语义逆向修正。中性词主导+隐含担忧的复合信号符合低度负面评分档位-0.5。\\\\n情绪得分:-0.5\\\\n\\\\n示例5（消极）：\\\\n新闻：饱受美国次贷危机冲击的华尔街再次风云突变\\\\n情绪词：crash:-0.9,meltdown:-0.8\\\\n理由:①语义信息为华尔街受次贷危机冲击引发的市场动荡，此类全球金融中心的不稳定通常导致跨国资本避险情绪上升，对中国市场构成外溢风险；②关键情绪词验证：未直接匹配“crash”或“meltdown”，但“次贷危机冲击”与“风云突变”共同映射系统性风险（贴近meltdown的-0.8方向），叠加事件严重性突破常规调整范畴。极端负面事件的整体语义强度主导评分。\\\\n情绪得分:-1\\\\n\\\\n\\\\n**输出规范**\\\\n- 五档制强制选择\\\\n- 格式：{\"情绪得分\":\"...\"}\\\\n\\\\n\\\\n（情绪词典分值仅作语义方向参考）\\\\n<think>好的，我现在需要分析这条新闻的情绪得分。首先，新闻内容是：“以前，针对原材料价格低、企业生产规模小、铝型材巿场受塑钢冲击大的特点，把经营模式定位为薄利多销型。” \\\\n\\\\n首先，我要理解这句话的整体意思。这里在讨论过去的企业经营模式，指出原材料价格低、企业生产规模小、铝型材市场受塑钢冲击大的特点，然后将经营模式定位为薄利多销型。薄利多销通常意味着卖价较低，但利润相对较低，可能带来市场波动。\\\\n\\\\n接下来，检查情绪词典中的关键词。情绪词典里有undercuts:-0.3和undercut:-0.3。需要看看新闻中有没有这些词。\\\\n\\\\n新闻中提到“薄利多销型”，这里的“薄利”对应undercut，但“多销”是“undercut”的反义词，也就是“多销”对应undercut的正向。不过在词典里，“undercut”是-0.3，而“undercuts”是-0.3。这里句子中并没有直接出现“undercut”或“undercuts”，而是“薄利多销型”，可能只是描述经营模式，没有明确的负面词汇。\\\\n\\\\n接下来，分析整体语义。新闻提到的是过去的企业结构问题，强调薄利多销，但没有直接给出负面情绪的词汇，比如“亏本”或“亏损”。而是强调当前的市场状况，比如原材料价格低、企业生产规模小，铝型材市场受塑钢冲击大，这些可能暗示市场波动，但并没有明显的负面情绪如“亏损”或“负面竞争”。\\\\n\\\\n所以，整体来看，新闻主要是在陈述过去的问题，没有明显的负面词汇，也没有明显的积极情绪。因此，情绪得分应该在中性范围内，也就是0。\\\\n\\\\n再检查一下情绪词典的匹配。虽然没有直接出现“undercuts”或“undercut”，但“薄利多销型”可能暗示一些负面因素，但并没有明确的负面词汇。因此，整体上情绪应该是中性的。\\\\n\\\\n综上所述，新闻的情绪得分应该是0。\\\\n</think>\\\\n\\\\n{\"情绪得分\":\"0\"}<｜end▁of▁sentence｜>\\'}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[-1,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('output.csv',encoding = 'utf_8_sig',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fddead",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/root/LLM_news_emo_analyze/wxy_use/deepseek_test_500_wxy_0420.csv\", encoding='utf_8_sig', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706b71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeclareDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>NewsContent</th>\n",
       "      <th>NewsSource</th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>stratum</th>\n",
       "      <th>topic</th>\n",
       "      <th>similarity</th>\n",
       "      <th>prompt</th>\n",
       "      <th>cut_news</th>\n",
       "      <th>sentiment_dict</th>\n",
       "      <th>sentiment_dict_v2</th>\n",
       "      <th>qwen_input</th>\n",
       "      <th>deepseekk_content</th>\n",
       "      <th>reasoning_content</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>人工标注</th>\n",
       "      <th>FTdeepseek_output</th>\n",
       "      <th>FTdeepseek</th>\n",
       "      <th>deepseek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/1/2 0:00</td>\n",
       "      <td>元旦谁抢中国游客多？日本韩国，一个笑了一个哭了</td>\n",
       "      <td>“世界那么大，我想去看看。”这个元旦小长假，不少中国人就选择了境外游迎接跨年。 　　日前，携...</td>\n",
       "      <td>每日经济新闻</td>\n",
       "      <td>18-Jan</td>\n",
       "      <td>2018-01-02 00:00:00_每日经济新闻</td>\n",
       "      <td>“消费”</td>\n",
       "      <td>0.611313</td>\n",
       "      <td>新闻文本是##“携程跟团游、自由行数据，香港、曼谷、东京、新加坡、大阪、长滩岛、台北、芽庄、...</td>\n",
       "      <td>携程跟团游、自由行数据，香港、曼谷、东京、新加坡、大阪、长滩岛、台北、芽庄、迪拜、伊斯坦布尔...</td>\n",
       "      <td>海外的/国外的(overseas):0.0,外国的/国外的(foreign):0.0</td>\n",
       "      <td>overseas:0.0, foreign:0.0</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:0}</td>\n",
       "      <td>好的，我现在需要分析这条新闻的情绪得分。首先，看看新闻内容。主要讲的是携程的跟团游和自由行数...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;think&gt;好的，我现在需要分析给定的新闻文本，并根据提供的情绪词典进行情绪评分。首先，我...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012/2/12 0:00</td>\n",
       "      <td>让农民在家门口享受到金融服务</td>\n",
       "      <td>湖北省洪湖市周坊村，60岁的张远航如今在本村就能领取到养老保险金，是农业银行在村里设置的代...</td>\n",
       "      <td>经济日报</td>\n",
       "      <td>12-Feb</td>\n",
       "      <td>2012-02-12 00:00:00_经济日报</td>\n",
       "      <td>“消费”</td>\n",
       "      <td>0.570472</td>\n",
       "      <td>新闻文本是##“而福喜集团总部所在地的美国，更被称作是全球食品安全监管体系最完善的国家之一，...</td>\n",
       "      <td>而福喜集团总部所在地的美国，更被称作是全球食品安全监管体系最完善的国家之一，其着力于事前监管...</td>\n",
       "      <td>完美的/完善的(perfect):1.0,食物/食品(food):0.0</td>\n",
       "      <td>perfect:1.0, food:0.0</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:0}</td>\n",
       "      <td>好的，我现在需要处理这个用户的查询。首先，用户给了一个新闻文本，要求分析市场情绪，并根据给定...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;think&gt;好的，我现在需要分析这段新闻的情绪，并给出五档制评分。首先，我得仔细阅读新闻内...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020/9/1 0:00</td>\n",
       "      <td>人民币汇率为何持续走强</td>\n",
       "      <td>8月31日，中国人民银行授权中国外汇交易中心公布，人民币对美元汇率中间价报6.8605，上...</td>\n",
       "      <td>经济日报</td>\n",
       "      <td>20-Sep</td>\n",
       "      <td>2020-09-01 00:00:00_经济日报</td>\n",
       "      <td>“消费”</td>\n",
       "      <td>0.485701</td>\n",
       "      <td>新闻文本是##“其中指出，2021年全球受饥饿影响的人数已达8.28亿，较2020年增加约4...</td>\n",
       "      <td>其中指出，2021年全球受饥饿影响的人数已达8.28亿，较2020年增加约4600万，自新冠...</td>\n",
       "      <td>供应过剩(oversupply):-0.2,过量的/过剩的(excessive):-0.3</td>\n",
       "      <td>oversupply:-0.2, excessive:-0.3</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:-1}</td>\n",
       "      <td>好的，我现在要分析这条新闻的情绪得分。首先，新闻内容是关于2021年全球饥饿人数增加的情况，...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>&lt;think&gt;好的，我现在需要分析这条新闻的情绪得分。首先，新闻内容是关于全球受饥饿影响的人...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017/6/26 15:39</td>\n",
       "      <td>钮文新：不能宽容高杠杆的源头</td>\n",
       "      <td>文| CCTV证券资讯频道总编辑 钮文新\\n责编：赵泽\\n（本文刊发于《中国经济周刊》201...</td>\n",
       "      <td>中国经济周刊</td>\n",
       "      <td>17-Jun</td>\n",
       "      <td>2017-06-26 15:39:00_中国经济周刊</td>\n",
       "      <td>“消费”</td>\n",
       "      <td>0.456633</td>\n",
       "      <td>新闻文本是##“理论上，市场的过度竞争会导致所有参与者利润不断趋近于零，而生存的本能欲望，极...</td>\n",
       "      <td>理论上，市场的过度竞争会导致所有参与者利润不断趋近于零，而生存的本能欲望，极易导致“经营失德”</td>\n",
       "      <td>管理不善/管理失误(mismanagement):-0.5,无竞争力的(uncompetit...</td>\n",
       "      <td>mismanagement:-0.5, uncompetitive:-0.3</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:-1}</td>\n",
       "      <td>好的，我需要分析这段新闻文本的情绪，并根据给定的情绪词典进行评分。首先，看看新闻内容：“理论...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>&lt;think&gt;好的，我现在需要分析给定的新闻文本的情绪得分。首先，根据用户提供的角色定义，我...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024/5/30 14:23</td>\n",
       "      <td>​打通供应链，打造共赢链</td>\n",
       "      <td>《中国经济周刊》 记者 侯隽 | 北京报道\\n供应链话题正在被高度关注。\\n受贸易保护主义、...</td>\n",
       "      <td>中国经济周刊</td>\n",
       "      <td>24-May</td>\n",
       "      <td>2024-05-30 14:23:00_中国经济周刊</td>\n",
       "      <td>“生产投资”</td>\n",
       "      <td>0.676999</td>\n",
       "      <td>新闻文本是##“推动多边贸易体制，共同维护产业链供应链畅通\\n我国是全世界唯一拥有联合国产业...</td>\n",
       "      <td>推动多边贸易体制，共同维护产业链供应链畅通\\n我国是全世界唯一拥有联合国产业分类中全部工业门...</td>\n",
       "      <td>工业/产业(industry):0.0,工业的/产业的(industrial):0.0</td>\n",
       "      <td>industry:0.0, industrial:0.0</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:0.5}</td>\n",
       "      <td>好的，我来仔细分析一下这个新闻文本。首先，新闻内容主要讲的是中国作为唯一拥有全部工业门类的国...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;think&gt;好的，我需要分析这段新闻文本的情绪，并根据给定的情绪词典和评分逻辑给出五档制评...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2024/11/28 15:11</td>\n",
       "      <td>产融合作赋能新型工业化</td>\n",
       "      <td>《中国经济周刊》 记者 孙庭阳 郭霁瑶 |北京报道\\n制造业，是立国之本、强国之基。当前我国...</td>\n",
       "      <td>中国经济周刊</td>\n",
       "      <td>24-Nov</td>\n",
       "      <td>2024-11-28 15:11:00_中国经济周刊</td>\n",
       "      <td>“生产投资”</td>\n",
       "      <td>0.538206</td>\n",
       "      <td>新闻文本是##“”上述负责人介绍，“基金额度循环使用，即企业结清贷款后，相应额度会释放出来，...</td>\n",
       "      <td>”上述负责人介绍，“基金额度循环使用，即企业结清贷款后，相应额度会释放出来，供有需要的企业继...</td>\n",
       "      <td>基金/资金(fund):0.1,基本的/根本的(fundamental):0.3</td>\n",
       "      <td>fund:0.1, fundamental:0.3</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:0}</td>\n",
       "      <td>好的，我现在需要处理这个市场情绪分析的任务。首先，我得仔细阅读用户提供的所有信息，确保自己理...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2007/1/14 0:00</td>\n",
       "      <td>村里超市开业了</td>\n",
       "      <td>1月7日，星期天，记者在山东省文登市采访。雪后路滑，气温较低，但却是晴朗朗的好天气。听说文登...</td>\n",
       "      <td>经济日报</td>\n",
       "      <td>7-Jan</td>\n",
       "      <td>2007-01-14 00:00:00_经济日报</td>\n",
       "      <td>“消费”</td>\n",
       "      <td>0.547639</td>\n",
       "      <td>新闻文本是##“现在农村有了超市，好多假货彻底失去了市场”##，包含的情绪词典是##：无销路...</td>\n",
       "      <td>现在农村有了超市，好多假货彻底失去了市场</td>\n",
       "      <td>无销路的/滞销的(unmarketable):-0.5,滞销(unsellable):-0.4</td>\n",
       "      <td>unmarketable:-0.5, unsellable:-0.4</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:1}</td>\n",
       "      <td>好的，我需要分析这条新闻的情绪。新闻内容是：“现在农村有了超市，好多假货彻底失去了市场。”首...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2024/3/30 0:08</td>\n",
       "      <td>如何错误地防范金融危机</td>\n",
       "      <td>韩明睿不少大众社科书籍都有一个抓人眼球但不太容易看出是什么主题的书名，副标题则是解释性质的“...</td>\n",
       "      <td>经济观察报</td>\n",
       "      <td>24-Mar</td>\n",
       "      <td>2024-03-30 00:08:00_经济观察报</td>\n",
       "      <td>“生产投资”</td>\n",
       "      <td>0.526640</td>\n",
       "      <td>新闻文本是##“在全球气候变化挑战日益严峻的大背景下，欧洲迎来绿色转型大潮，其中以法国为代表...</td>\n",
       "      <td>在全球气候变化挑战日益严峻的大背景下，欧洲迎来绿色转型大潮，其中以法国为代表的部分国家将发展...</td>\n",
       "      <td>气候/环境(climate):0.0,法国的/法语的(french):0.0</td>\n",
       "      <td>climate:0.0, french:0.0</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:0}</td>\n",
       "      <td>好的，我需要分析给定的新闻文本的情绪得分。首先，仔细阅读新闻内容。新闻讲的是欧洲特别是法国在...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2024/4/30 15:37</td>\n",
       "      <td>​积极推进新型城镇化，各类要素如何双向流动</td>\n",
       "      <td>文| 尹稚\\n2023年底召开的中央经济工作会议指出，要把推进新型城镇化和乡村全面振兴有机结...</td>\n",
       "      <td>中国经济周刊</td>\n",
       "      <td>24-Apr</td>\n",
       "      <td>2024-04-30 15:37:00_中国经济周刊</td>\n",
       "      <td>“房地产”</td>\n",
       "      <td>0.634848</td>\n",
       "      <td>新闻文本是##“规划时，一些地方官员没有考虑到当地的具体情况，易导致出现不良资产，尤其是个别...</td>\n",
       "      <td>规划时，一些地方官员没有考虑到当地的具体情况，易导致出现不良资产，尤其是个别人口流出地区，还...</td>\n",
       "      <td>未充分利用(underutilization):-0.3,管理不善/错误管理(mismana...</td>\n",
       "      <td>underutilization:-0.3, mismanage:-0.4</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:-0.5}</td>\n",
       "      <td>好的，我现在需要分析这篇新闻文本的情绪得分。首先，新闻内容是关于地方官员在规划时没有考虑当地...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2020/2/16 0:00</td>\n",
       "      <td>在中央政治局常委会会议研究应对新型冠状病毒肺炎疫情工作时的讲话</td>\n",
       "      <td>新华社北京2月15日电 2月16日出版的今年第4期《求是》杂志将发表中共中央总书记、国家主...</td>\n",
       "      <td>经济日报</td>\n",
       "      <td>20-Feb</td>\n",
       "      <td>2020-02-16 00:00:00_经济日报</td>\n",
       "      <td>“生产投资”</td>\n",
       "      <td>0.516709</td>\n",
       "      <td>新闻文本是##“以前，针对原材料价格低、企业生产规模小、铝型材巿场受塑钢冲击大的特点，把经营...</td>\n",
       "      <td>以前，针对原材料价格低、企业生产规模小、铝型材巿场受塑钢冲击大的特点，把经营模式定位为薄利多销型</td>\n",
       "      <td>削价/低价出售(undercuts):-0.3,削价/低价出售(undercut):-0.3</td>\n",
       "      <td>undercuts:-0.3, undercut:-0.3</td>\n",
       "      <td>**角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...</td>\n",
       "      <td>{情绪得分:-0.5}</td>\n",
       "      <td>好的，我现在需要分析给定的新闻文本的情绪，并根据提供的评分标准给出五档制中的得分。首先，我得...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DeclareDate                            Title  \\\n",
       "0       2018/1/2 0:00          元旦谁抢中国游客多？日本韩国，一个笑了一个哭了   \n",
       "1      2012/2/12 0:00                   让农民在家门口享受到金融服务   \n",
       "2       2020/9/1 0:00                     人民币汇率为何持续走强    \n",
       "3     2017/6/26 15:39                   钮文新：不能宽容高杠杆的源头   \n",
       "4     2024/5/30 14:23                     ​打通供应链，打造共赢链   \n",
       "..                ...                              ...   \n",
       "495  2024/11/28 15:11                      产融合作赋能新型工业化   \n",
       "496    2007/1/14 0:00                          村里超市开业了   \n",
       "497    2024/3/30 0:08                      如何错误地防范金融危机   \n",
       "498   2024/4/30 15:37            ​积极推进新型城镇化，各类要素如何双向流动   \n",
       "499    2020/2/16 0:00  在中央政治局常委会会议研究应对新型冠状病毒肺炎疫情工作时的讲话   \n",
       "\n",
       "                                           NewsContent NewsSource yearmonth  \\\n",
       "0    “世界那么大，我想去看看。”这个元旦小长假，不少中国人就选择了境外游迎接跨年。 　　日前，携...     每日经济新闻    18-Jan   \n",
       "1     湖北省洪湖市周坊村，60岁的张远航如今在本村就能领取到养老保险金，是农业银行在村里设置的代...       经济日报    12-Feb   \n",
       "2     8月31日，中国人民银行授权中国外汇交易中心公布，人民币对美元汇率中间价报6.8605，上...       经济日报    20-Sep   \n",
       "3    文| CCTV证券资讯频道总编辑 钮文新\\n责编：赵泽\\n（本文刊发于《中国经济周刊》201...     中国经济周刊    17-Jun   \n",
       "4    《中国经济周刊》 记者 侯隽 | 北京报道\\n供应链话题正在被高度关注。\\n受贸易保护主义、...     中国经济周刊    24-May   \n",
       "..                                                 ...        ...       ...   \n",
       "495  《中国经济周刊》 记者 孙庭阳 郭霁瑶 |北京报道\\n制造业，是立国之本、强国之基。当前我国...     中国经济周刊    24-Nov   \n",
       "496  1月7日，星期天，记者在山东省文登市采访。雪后路滑，气温较低，但却是晴朗朗的好天气。听说文登...       经济日报     7-Jan   \n",
       "497  韩明睿不少大众社科书籍都有一个抓人眼球但不太容易看出是什么主题的书名，副标题则是解释性质的“...      经济观察报    24-Mar   \n",
       "498  文| 尹稚\\n2023年底召开的中央经济工作会议指出，要把推进新型城镇化和乡村全面振兴有机结...     中国经济周刊    24-Apr   \n",
       "499   新华社北京2月15日电 2月16日出版的今年第4期《求是》杂志将发表中共中央总书记、国家主...       经济日报    20-Feb   \n",
       "\n",
       "                        stratum   topic  similarity  \\\n",
       "0    2018-01-02 00:00:00_每日经济新闻    “消费”    0.611313   \n",
       "1      2012-02-12 00:00:00_经济日报    “消费”    0.570472   \n",
       "2      2020-09-01 00:00:00_经济日报    “消费”    0.485701   \n",
       "3    2017-06-26 15:39:00_中国经济周刊    “消费”    0.456633   \n",
       "4    2024-05-30 14:23:00_中国经济周刊  “生产投资”    0.676999   \n",
       "..                          ...     ...         ...   \n",
       "495  2024-11-28 15:11:00_中国经济周刊  “生产投资”    0.538206   \n",
       "496    2007-01-14 00:00:00_经济日报    “消费”    0.547639   \n",
       "497   2024-03-30 00:08:00_经济观察报  “生产投资”    0.526640   \n",
       "498  2024-04-30 15:37:00_中国经济周刊   “房地产”    0.634848   \n",
       "499    2020-02-16 00:00:00_经济日报  “生产投资”    0.516709   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    新闻文本是##“携程跟团游、自由行数据，香港、曼谷、东京、新加坡、大阪、长滩岛、台北、芽庄、...   \n",
       "1    新闻文本是##“而福喜集团总部所在地的美国，更被称作是全球食品安全监管体系最完善的国家之一，...   \n",
       "2    新闻文本是##“其中指出，2021年全球受饥饿影响的人数已达8.28亿，较2020年增加约4...   \n",
       "3    新闻文本是##“理论上，市场的过度竞争会导致所有参与者利润不断趋近于零，而生存的本能欲望，极...   \n",
       "4    新闻文本是##“推动多边贸易体制，共同维护产业链供应链畅通\\n我国是全世界唯一拥有联合国产业...   \n",
       "..                                                 ...   \n",
       "495  新闻文本是##“”上述负责人介绍，“基金额度循环使用，即企业结清贷款后，相应额度会释放出来，...   \n",
       "496  新闻文本是##“现在农村有了超市，好多假货彻底失去了市场”##，包含的情绪词典是##：无销路...   \n",
       "497  新闻文本是##“在全球气候变化挑战日益严峻的大背景下，欧洲迎来绿色转型大潮，其中以法国为代表...   \n",
       "498  新闻文本是##“规划时，一些地方官员没有考虑到当地的具体情况，易导致出现不良资产，尤其是个别...   \n",
       "499  新闻文本是##“以前，针对原材料价格低、企业生产规模小、铝型材巿场受塑钢冲击大的特点，把经营...   \n",
       "\n",
       "                                              cut_news  \\\n",
       "0    携程跟团游、自由行数据，香港、曼谷、东京、新加坡、大阪、长滩岛、台北、芽庄、迪拜、伊斯坦布尔...   \n",
       "1    而福喜集团总部所在地的美国，更被称作是全球食品安全监管体系最完善的国家之一，其着力于事前监管...   \n",
       "2    其中指出，2021年全球受饥饿影响的人数已达8.28亿，较2020年增加约4600万，自新冠...   \n",
       "3      理论上，市场的过度竞争会导致所有参与者利润不断趋近于零，而生存的本能欲望，极易导致“经营失德”   \n",
       "4    推动多边贸易体制，共同维护产业链供应链畅通\\n我国是全世界唯一拥有联合国产业分类中全部工业门...   \n",
       "..                                                 ...   \n",
       "495  ”上述负责人介绍，“基金额度循环使用，即企业结清贷款后，相应额度会释放出来，供有需要的企业继...   \n",
       "496                               现在农村有了超市，好多假货彻底失去了市场   \n",
       "497  在全球气候变化挑战日益严峻的大背景下，欧洲迎来绿色转型大潮，其中以法国为代表的部分国家将发展...   \n",
       "498  规划时，一些地方官员没有考虑到当地的具体情况，易导致出现不良资产，尤其是个别人口流出地区，还...   \n",
       "499   以前，针对原材料价格低、企业生产规模小、铝型材巿场受塑钢冲击大的特点，把经营模式定位为薄利多销型   \n",
       "\n",
       "                                        sentiment_dict  \\\n",
       "0           海外的/国外的(overseas):0.0,外国的/国外的(foreign):0.0   \n",
       "1                 完美的/完善的(perfect):1.0,食物/食品(food):0.0   \n",
       "2        供应过剩(oversupply):-0.2,过量的/过剩的(excessive):-0.3   \n",
       "3    管理不善/管理失误(mismanagement):-0.5,无竞争力的(uncompetit...   \n",
       "4          工业/产业(industry):0.0,工业的/产业的(industrial):0.0   \n",
       "..                                                 ...   \n",
       "495           基金/资金(fund):0.1,基本的/根本的(fundamental):0.3   \n",
       "496    无销路的/滞销的(unmarketable):-0.5,滞销(unsellable):-0.4   \n",
       "497             气候/环境(climate):0.0,法国的/法语的(french):0.0   \n",
       "498  未充分利用(underutilization):-0.3,管理不善/错误管理(mismana...   \n",
       "499     削价/低价出售(undercuts):-0.3,削价/低价出售(undercut):-0.3   \n",
       "\n",
       "                          sentiment_dict_v2  \\\n",
       "0                 overseas:0.0, foreign:0.0   \n",
       "1                     perfect:1.0, food:0.0   \n",
       "2           oversupply:-0.2, excessive:-0.3   \n",
       "3    mismanagement:-0.5, uncompetitive:-0.3   \n",
       "4              industry:0.0, industrial:0.0   \n",
       "..                                      ...   \n",
       "495               fund:0.1, fundamental:0.3   \n",
       "496      unmarketable:-0.5, unsellable:-0.4   \n",
       "497                 climate:0.0, french:0.0   \n",
       "498   underutilization:-0.3, mismanage:-0.4   \n",
       "499           undercuts:-0.3, undercut:-0.3   \n",
       "\n",
       "                                            qwen_input deepseekk_content  \\\n",
       "0    **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...          {情绪得分:0}   \n",
       "1    **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...          {情绪得分:0}   \n",
       "2    **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...         {情绪得分:-1}   \n",
       "3    **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...         {情绪得分:-1}   \n",
       "4    **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...        {情绪得分:0.5}   \n",
       "..                                                 ...               ...   \n",
       "495  **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...          {情绪得分:0}   \n",
       "496  **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...          {情绪得分:1}   \n",
       "497  **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...          {情绪得分:0}   \n",
       "498  **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...       {情绪得分:-0.5}   \n",
       "499  **角色定义**\\n擅长中英双语的市场情绪分析专家，能够对中国市场的新闻文本情绪进行准确的评...       {情绪得分:-0.5}   \n",
       "\n",
       "                                     reasoning_content  Unnamed: 15  人工标注  \\\n",
       "0    好的，我现在需要分析这条新闻的情绪得分。首先，看看新闻内容。主要讲的是携程的跟团游和自由行数...          NaN   0.0   \n",
       "1    好的，我现在需要处理这个用户的查询。首先，用户给了一个新闻文本，要求分析市场情绪，并根据给定...          NaN   0.0   \n",
       "2    好的，我现在要分析这条新闻的情绪得分。首先，新闻内容是关于2021年全球饥饿人数增加的情况，...          NaN  -1.0   \n",
       "3    好的，我需要分析这段新闻文本的情绪，并根据给定的情绪词典进行评分。首先，看看新闻内容：“理论...          NaN  -1.0   \n",
       "4    好的，我来仔细分析一下这个新闻文本。首先，新闻内容主要讲的是中国作为唯一拥有全部工业门类的国...          NaN   0.0   \n",
       "..                                                 ...          ...   ...   \n",
       "495  好的，我现在需要处理这个市场情绪分析的任务。首先，我得仔细阅读用户提供的所有信息，确保自己理...          NaN   0.0   \n",
       "496  好的，我需要分析这条新闻的情绪。新闻内容是：“现在农村有了超市，好多假货彻底失去了市场。”首...          NaN   1.0   \n",
       "497  好的，我需要分析给定的新闻文本的情绪得分。首先，仔细阅读新闻内容。新闻讲的是欧洲特别是法国在...          NaN   0.5   \n",
       "498  好的，我现在需要分析这篇新闻文本的情绪得分。首先，新闻内容是关于地方官员在规划时没有考虑当地...          NaN  -0.5   \n",
       "499  好的，我现在需要分析给定的新闻文本的情绪，并根据提供的评分标准给出五档制中的得分。首先，我得...          NaN   0.0   \n",
       "\n",
       "                                     FTdeepseek_output  FTdeepseek  deepseek  \n",
       "0    <think>好的，我现在需要分析给定的新闻文本，并根据提供的情绪词典进行情绪评分。首先，我...         0.0       0.0  \n",
       "1    <think>好的，我现在需要分析这段新闻的情绪，并给出五档制评分。首先，我得仔细阅读新闻内...         0.5       0.0  \n",
       "2    <think>好的，我现在需要分析这条新闻的情绪得分。首先，新闻内容是关于全球受饥饿影响的人...         0.0      -1.0  \n",
       "3    <think>好的，我现在需要分析给定的新闻文本的情绪得分。首先，根据用户提供的角色定义，我...         0.0      -1.0  \n",
       "4    <think>好的，我需要分析这段新闻文本的情绪，并根据给定的情绪词典和评分逻辑给出五档制评...         0.0       0.5  \n",
       "..                                                 ...         ...       ...  \n",
       "495                                                NaN         NaN       0.0  \n",
       "496                                                NaN         NaN       1.0  \n",
       "497                                                NaN         NaN       0.0  \n",
       "498                                                NaN         NaN      -0.5  \n",
       "499                                                NaN         NaN      -0.5  \n",
       "\n",
       "[500 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625b42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek_sft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
